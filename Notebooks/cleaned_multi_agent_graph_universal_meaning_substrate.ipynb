{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e0e06d",
   "metadata": {},
   "source": [
    "# Multi-Agent Graph Similarity Validation Experiment\n",
    "# Enhanced and Cleaned Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0a7c7",
   "metadata": {},
   "source": [
    "\n",
    "## Objective\n",
    "Test whether multiple agents independently build similar semantic graph structures when trained on ConceptNet data with injected false triples. This experiment validates the hypothesis of a universal theory of meaning that is self-reinforcing, rejects contradiction, and shows clear paths of reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f0bdb",
   "metadata": {},
   "source": [
    "\n",
    "## Experimental Design\n",
    "- **Agents**: 5-10 independent agents\n",
    "- **Data Source**: ConceptNet triples with randomly generated false triples injected\n",
    "- **Training**: No filters, agents can ACCEPT/REJECT/REVIEW triples\n",
    "- **Validation**: Measure graph similarity, structure, and false triple influence\n",
    "- **Scalability**: Designed to scale from small experiments to full 3M dataset\n",
    "\n",
    "## Key Hypothesis\n",
    "If multiple agents build similar semantic structures without shared optimization or influence, this provides evidence for a fundamental theory of meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e23ae4",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 1: IMPORTS AND CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c829dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Experiment started at: 2025-05-27 16:30:07.719483\n",
      "Configuration:\n",
      "  experiment_name: multi_agent_validation_v1\n",
      "  num_agents: 7\n",
      "  num_epochs: 10\n",
      "  max_iterations: 100\n",
      "  false_triple_ratio: 0.1\n",
      "  batch_size: 100\n",
      "  validation_threshold: 0.7\n",
      "  sample_size: 50000\n",
      "  quality_threshold: 0.8\n",
      "  similarity_metrics: ['jaccard', 'weighted_jaccard', 'structural', 'semantic', 'path_based']\n",
      "  save_checkpoints: True\n",
      "  verbose: True\n",
      "  epoch_verbose: True\n",
      "  dataset_coverage_per_epoch: 0.8\n",
      "  max_resolution_attempts_per_batch: 50\n",
      "  top_weight_resolution_limit: 100\n",
      "  enable_relation_suggestions: True\n",
      "  suggestion_frequency: 0.2\n",
      "  max_suggestions_per_batch: 15\n",
      "  suggestion_confidence_threshold: 0.6\n",
      "  suggestion_diversity_factor: 0.3\n",
      "  suggestion_graph_exploration_depth: 2\n",
      "  min_graph_size_for_suggestions: 10\n",
      "  suggestion_novelty_weight: 0.4\n",
      "  suggestion_semantic_weight: 0.6\n",
      "  adaptive_training_mode: False\n",
      "  coverage_based_training: False\n",
      "  target_coverage: 0.9\n",
      "  coverage_timeout_minutes: 15\n",
      "  coverage_max_iterations: 500\n",
      "  fallback_to_epochs: True\n",
      "  coverage_check_frequency: 10\n",
      "  coverage_progress_threshold: 0.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score, adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Experiment started at: {datetime.now()}\")\n",
    "\n",
    "# EXPERIMENTAL CONFIGURATION\n",
    "\n",
    "CONFIG = {\n",
    "    'experiment_name': 'multi_agent_validation_v1',\n",
    "    'num_agents': 7,  # Start with 7 agents for comprehensive comparison\n",
    "    'num_epochs': 10,  # Number of complete passes through the dataset\n",
    "    'max_iterations': 100,  # Training iterations per epoch\n",
    "    'false_triple_ratio': 0.1,  # 10% false triples injected\n",
    "    'batch_size': 100,  # Triples per training batch\n",
    "    'validation_threshold': 0.7,  # Agent validation confidence threshold\n",
    "    'sample_size': 50_000,  # Initial sample from ConceptNet (scalable)\n",
    "    'quality_threshold': 0.8,  # Minimum quality for triple acceptance\n",
    "    'similarity_metrics': ['jaccard', 'weighted_jaccard', 'structural', 'semantic', 'path_based'],\n",
    "    'save_checkpoints': True,\n",
    "    'verbose': True,\n",
    "    'epoch_verbose': True,  # Verbose reporting at epoch level\n",
    "    'dataset_coverage_per_epoch': 0.8,  # Fraction of dataset to cover per epoch (for robustness)\n",
    "    \n",
    "    # === RESOLUTION CONFIGURATION ===\n",
    "    'max_resolution_attempts_per_batch': 50,  # Maximum relations to attempt resolution per batch\n",
    "    'top_weight_resolution_limit': 100,  # Only consider top N highest-weighted pending relations\n",
    "    \n",
    "    # === RELATION SUGGESTION CONFIGURATION ===\n",
    "    'enable_relation_suggestions': True,  # Enable proactive relation suggestion\n",
    "    'suggestion_frequency': 0.2,  # Frequency of suggesting new relations (0.0-1.0)\n",
    "    'max_suggestions_per_batch': 15,  # Maximum number of suggestions to generate per batch\n",
    "    'suggestion_confidence_threshold': 0.6,  # Minimum confidence for suggesting a relation\n",
    "    'suggestion_diversity_factor': 0.3,  # Factor to encourage diverse relation types in suggestions\n",
    "    'suggestion_graph_exploration_depth': 2,  # How many hops to explore for suggestions\n",
    "    'min_graph_size_for_suggestions': 10,  # Minimum graph size before starting suggestions\n",
    "    'suggestion_novelty_weight': 0.4,  # Weight for novelty in suggestion scoring\n",
    "    'suggestion_semantic_weight': 0.6,  # Weight for semantic similarity in suggestion scoring\n",
    "    \n",
    "    # === ADAPTIVE TRAINING CONFIGURATION ===\n",
    "    'adaptive_training_mode': False,  # Enable intelligent training mode switching\n",
    "    'coverage_based_training': False,  # Try coverage-based training first\n",
    "    'target_coverage': 0.9,  # 90% coverage target for coverage-based training\n",
    "    'coverage_timeout_minutes': 15,  # Max time to spend on coverage-based training\n",
    "    'coverage_max_iterations': 500,  # Max iterations for coverage-based training\n",
    "    'fallback_to_epochs': True,  # Fall back to epoch-based if coverage fails\n",
    "    'coverage_check_frequency': 10,  # Check coverage every N iterations\n",
    "    'coverage_progress_threshold': 0.01,  # Minimum progress required every 50 iterations\n",
    "}\n",
    "\n",
    "# File paths\n",
    "path_dir = r'C:\\Users\\erich\\OneDrive\\Documents\\Python Projects\\Semantica-Full-Reasoning-Chatbot\\Data'\n",
    "DATA_PATH = Path(path_dir) / 'Input'\n",
    "OUTPUT_PATH = Path(path_dir) / 'Output'\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c8778",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 2: VALIDATION AGENT CLASS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47eedd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidationAgent class defined successfully\n"
     ]
    }
   ],
   "source": [
    "class ValidationAgent:\n",
    "    \"\"\"\n",
    "    Independent validation agent for semantic graph construction\n",
    "    \n",
    "    ENHANCED RESOLUTION LOGIC:\n",
    "    - Try to validate a triple → if uncertain, goes to REVIEW\n",
    "    - After each batch, attempt to resolve pending REVIEW relations (prioritized by weight)\n",
    "    - Only attempt resolution on top N highest-weighted pending relations\n",
    "    - Configurable limit on resolution attempts per batch\n",
    "    - Each relation can only be reviewed maximum 5 times per epoch\n",
    "    - If after 5 review attempts it's still unresolved → stays in REVIEW for rest of epoch (epoch locked)\n",
    "    - At epoch end, reset both attempt counts and review counts for fresh integration\n",
    "    \n",
    "    RELATION SUGGESTION CAPABILITIES:\n",
    "    - Proactively generate new relation suggestions based on current graph structure\n",
    "    - Use graph exploration and pattern analysis to suggest likely relations\n",
    "    - Track suggestion performance and accuracy over time\n",
    "    - Configurable suggestion frequency and confidence thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agent_id, config):\n",
    "        self.agent_id = agent_id\n",
    "        self.config = config\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.validation_history = []\n",
    "        self.decision_log = {'ACCEPT': 0, 'REJECT': 0, 'REVIEW': 0, 'FORCED_DECISION': 0}\n",
    "        self.quality_scores = []\n",
    "        \n",
    "        # Enhanced tracking for relation resolution\n",
    "        self.relation_attempts = {}  # Track attempts per relation per batch cycle\n",
    "        self.relation_review_count = {}  # Track total reviews per relation per epoch\n",
    "        self.pending_relations = {}  # Store relations under review\n",
    "        \n",
    "        # === RELATION SUGGESTION TRACKING ===\n",
    "        self.suggested_relations = {}  # Track suggested relations and their outcomes\n",
    "        self.suggestion_history = []  # Track all suggestions made\n",
    "        self.suggestions_accepted = 0  # Count of suggestions that were accepted\n",
    "        self.suggestions_rejected = 0  # Count of suggestions that were rejected\n",
    "        self.suggestion_scores = []  # Track suggestion confidence scores\n",
    "        \n",
    "        self.training_metrics = {\n",
    "            'iterations_completed': 0,\n",
    "            'epochs_completed': 0,\n",
    "            'triples_processed': 0,\n",
    "            'false_triples_detected': 0,\n",
    "            'accuracy': 0.0,\n",
    "            'epoch_accuracies': [],  # Track accuracy across epochs\n",
    "            'epoch_nodes': [],       # Track graph size across epochs\n",
    "            'epoch_edges': [],\n",
    "            'relations_resolved': 0,  # Track successful resolutions\n",
    "            'forced_decisions': 0,    # Track forced decisions\n",
    "            'resolution_attempts_per_batch': [],  # Track resolution workload per batch\n",
    "            'top_weight_resolutions': 0,  # Track how many top-weight relations were resolved\n",
    "            \n",
    "            # === SUGGESTION METRICS ===\n",
    "            'suggestions_generated': 0,  # Total suggestions generated\n",
    "            'suggestions_accepted': 0,   # Suggestions that were validated and accepted\n",
    "            'suggestions_rejected': 0,   # Suggestions that were validated and rejected\n",
    "            'suggestion_accuracy': 0.0,  # Accuracy of suggestion validation\n",
    "            'avg_suggestion_confidence': 0.0,  # Average confidence of suggestions\n",
    "            'suggestion_diversity': 0.0,  # Diversity of suggested relation types\n",
    "        }\n",
    "        \n",
    "    def calculate_validation_score(self, triple, edge_weight=1.0):\n",
    "        \"\"\"Calculate validation score for a triple based on existing graph context\"\"\"\n",
    "        subj, rel, obj = triple\n",
    "        \n",
    "        # Base score influenced by edge weight\n",
    "        score = 0.4 + (edge_weight * 0.1)  # Higher weights get slightly higher base scores\n",
    "        \n",
    "        # Check for existing relationships\n",
    "        if self.graph.has_node(subj) and self.graph.has_node(obj):\n",
    "            # Check for direct connection\n",
    "            if self.graph.has_edge(subj, obj):\n",
    "                existing_rel = self.graph[subj][obj].get('relation', '')\n",
    "                existing_weight = self.graph[subj][obj].get('weight', 1.0)\n",
    "                \n",
    "                if existing_rel == rel:\n",
    "                    # Strengthen score based on weight consistency\n",
    "                    weight_consistency = 1 - abs(existing_weight - edge_weight) / max(existing_weight, edge_weight)\n",
    "                    score += 0.3 * weight_consistency\n",
    "                else:\n",
    "                    score -= 0.1  # Potential contradiction\n",
    "            \n",
    "            # Check for semantic consistency\n",
    "            subj_neighbors = set(self.graph.neighbors(subj))\n",
    "            obj_neighbors = set(self.graph.neighbors(obj))\n",
    "            common_neighbors = len(subj_neighbors.intersection(obj_neighbors))\n",
    "            \n",
    "            if common_neighbors > 0:\n",
    "                score += min(0.2, common_neighbors * 0.05)\n",
    "        \n",
    "        # Edge weight influence on validation\n",
    "        if edge_weight >= 0.8:\n",
    "            score += 0.1  # High confidence triples get bonus\n",
    "        elif edge_weight <= 0.3:\n",
    "            score -= 0.1  # Low confidence triples get penalty\n",
    "        \n",
    "        # Add noise for realism\n",
    "        score += np.random.normal(0, 0.05)\n",
    "        \n",
    "        return max(0.0, min(1.0, score))\n",
    "    \n",
    "    def validate_triple(self, triple, edge_weight=1.0, is_false=False, force_decision=False):\n",
    "        \"\"\"Enhanced validate triple with proper epoch locking and resolution forcing logic\"\"\"\n",
    "        triple_key = str(triple)\n",
    "        \n",
    "        # Initialize tracking for new relations\n",
    "        if triple_key not in self.relation_attempts:\n",
    "            self.relation_attempts[triple_key] = 0\n",
    "            self.relation_review_count[triple_key] = 0\n",
    "        \n",
    "        # Check if this relation is epoch-locked (exceeded 5 reviews this epoch)\n",
    "        if triple_key in self.pending_relations and self.pending_relations[triple_key].get('epoch_locked', False):\n",
    "            # Return REVIEW and don't process further this epoch\n",
    "            self.decision_log['REVIEW'] += 1\n",
    "            \n",
    "            self.validation_history.append({\n",
    "                'triple': triple,\n",
    "                'edge_weight': edge_weight,\n",
    "                'score': 0.5,  # Neutral score for locked relations\n",
    "                'decision': 'REVIEW',\n",
    "                'is_false': is_false,\n",
    "                'correct': None,  # Cannot determine correctness for locked relations\n",
    "                'attempt_number': self.relation_attempts[triple_key] + 1,\n",
    "                'total_reviews': self.relation_review_count[triple_key],\n",
    "                'forced': False,\n",
    "                'epoch_locked': True,\n",
    "                'epoch': self.training_metrics['epochs_completed'],\n",
    "                'iteration': self.training_metrics['iterations_completed']\n",
    "            })\n",
    "            \n",
    "            return 'REVIEW', 0.5\n",
    "        \n",
    "        # Calculate base validation score\n",
    "        score = self.calculate_validation_score(triple, edge_weight)\n",
    "        \n",
    "        # Enhanced decision logic with forced resolution\n",
    "        quality_threshold = self.config['quality_threshold']\n",
    "        \n",
    "        # Adjust thresholds based on edge weight\n",
    "        if edge_weight >= 0.8:\n",
    "            accept_threshold = quality_threshold - 0.1  # Lower threshold for high-weight triples\n",
    "            reject_threshold = 0.3\n",
    "        elif edge_weight <= 0.3:\n",
    "            accept_threshold = quality_threshold + 0.1  # Higher threshold for low-weight triples\n",
    "            reject_threshold = 0.4\n",
    "        else:\n",
    "            accept_threshold = quality_threshold\n",
    "            reject_threshold = 0.3\n",
    "        \n",
    "        # Check if we need to force a decision\n",
    "        attempts = self.relation_attempts[triple_key]\n",
    "        total_reviews = self.relation_review_count[triple_key]\n",
    "        \n",
    "        if force_decision or attempts >= 3 or total_reviews >= 5:\n",
    "            # Force a binary decision (ACCEPT or REJECT only)\n",
    "            if score >= (accept_threshold + reject_threshold) / 2:\n",
    "                decision = 'ACCEPT'\n",
    "            else:\n",
    "                decision = 'REJECT'\n",
    "            \n",
    "            if attempts >= 3 or total_reviews >= 5:\n",
    "                self.decision_log['FORCED_DECISION'] += 1\n",
    "                self.training_metrics['forced_decisions'] += 1\n",
    "                \n",
    "        else:\n",
    "            # Normal decision logic with review capability\n",
    "            if score >= accept_threshold:\n",
    "                decision = 'ACCEPT'\n",
    "            elif score <= reject_threshold:\n",
    "                decision = 'REJECT'\n",
    "            else:\n",
    "                decision = 'REVIEW'\n",
    "                self.relation_review_count[triple_key] += 1\n",
    "                \n",
    "                # Calculate priority weight for pending relation\n",
    "                priority_weight = self._calculate_priority_weight(triple, edge_weight, score)\n",
    "                \n",
    "                # Add to pending relations or update existing entry\n",
    "                self.pending_relations[triple_key] = {\n",
    "                    'triple': triple,\n",
    "                    'edge_weight': edge_weight,\n",
    "                    'is_false': is_false,\n",
    "                    'attempts': attempts,\n",
    "                    'epoch_locked': False,  # Initialize as not locked\n",
    "                    'priority_weight': priority_weight,  # Add priority scoring\n",
    "                    'last_score': score  # Track latest validation score\n",
    "                }\n",
    "                \n",
    "                # Check if this relation should be epoch-locked\n",
    "                if self.relation_review_count[triple_key] >= 5:\n",
    "                    self.pending_relations[triple_key]['epoch_locked'] = True\n",
    "        \n",
    "        # Update attempt counter for this relation\n",
    "        self.relation_attempts[triple_key] += 1\n",
    "        \n",
    "        # Track performance\n",
    "        self.decision_log[decision] += 1\n",
    "        correct = (decision == 'REJECT') if is_false else (decision == 'ACCEPT')\n",
    "        \n",
    "        if decision in ['ACCEPT', 'REJECT']:\n",
    "            self.training_metrics['relations_resolved'] += 1\n",
    "            # Remove from pending if resolved\n",
    "            if triple_key in self.pending_relations:\n",
    "                del self.pending_relations[triple_key]\n",
    "        \n",
    "        self.validation_history.append({\n",
    "            'triple': triple,\n",
    "            'edge_weight': edge_weight,\n",
    "            'score': score,\n",
    "            'decision': decision,\n",
    "            'is_false': is_false,\n",
    "            'correct': correct,\n",
    "            'attempt_number': attempts + 1,\n",
    "            'total_reviews': self.relation_review_count[triple_key],\n",
    "            'forced': attempts >= 3 or total_reviews >= 5,\n",
    "            'epoch_locked': self.pending_relations.get(triple_key, {}).get('epoch_locked', False),\n",
    "            'epoch': self.training_metrics['epochs_completed'],\n",
    "            'iteration': self.training_metrics['iterations_completed']\n",
    "        })\n",
    "        \n",
    "        return decision, score\n",
    "    \n",
    "    def _calculate_priority_weight(self, triple, edge_weight, validation_score):\n",
    "        \"\"\"Calculate priority weight for pending relations based on multiple factors\"\"\"\n",
    "        # Base weight from edge weight (30% influence)\n",
    "        priority = edge_weight * 0.3\n",
    "        \n",
    "        # Validation score influence (40% influence)\n",
    "        priority += validation_score * 0.4\n",
    "        \n",
    "        # Graph connectivity influence (20% influence)\n",
    "        subj, rel, obj = triple\n",
    "        connectivity_score = 0\n",
    "        \n",
    "        if self.graph.has_node(subj):\n",
    "            connectivity_score += min(0.1, self.graph.degree(subj) * 0.01)\n",
    "        if self.graph.has_node(obj):\n",
    "            connectivity_score += min(0.1, self.graph.degree(obj) * 0.01)\n",
    "            \n",
    "        priority += connectivity_score * 0.2\n",
    "        \n",
    "        # Novelty bonus (10% influence) - prefer new concepts\n",
    "        novelty_bonus = 0\n",
    "        if not self.graph.has_node(subj):\n",
    "            novelty_bonus += 0.05\n",
    "        if not self.graph.has_node(obj):\n",
    "            novelty_bonus += 0.05\n",
    "            \n",
    "        priority += novelty_bonus * 0.1\n",
    "        \n",
    "        # Add small random component for tie-breaking\n",
    "        priority += np.random.uniform(0, 0.01)\n",
    "        \n",
    "        return max(0.0, min(1.0, priority))\n",
    "    \n",
    "    def generate_relation_suggestions(self):\n",
    "        \"\"\"Generate new relation suggestions based on current graph structure\"\"\"\n",
    "        if not self.config.get('enable_relation_suggestions', False):\n",
    "            return []\n",
    "            \n",
    "        # Don't suggest if graph is too small\n",
    "        if self.graph.number_of_nodes() < self.config.get('min_graph_size_for_suggestions', 10):\n",
    "            return []\n",
    "            \n",
    "        # Check if we should generate suggestions based on frequency\n",
    "        if np.random.random() > self.config.get('suggestion_frequency', 0.2):\n",
    "            return []\n",
    "            \n",
    "        suggestions = []\n",
    "        max_suggestions = self.config.get('max_suggestions_per_batch', 15)\n",
    "        confidence_threshold = self.config.get('suggestion_confidence_threshold', 0.6)\n",
    "        exploration_depth = self.config.get('suggestion_graph_exploration_depth', 2)\n",
    "        \n",
    "        # Get all nodes for potential suggestion candidates\n",
    "        nodes = list(self.graph.nodes())\n",
    "        if len(nodes) < 2:\n",
    "            return []\n",
    "            \n",
    "        # Get existing relation types to encourage diversity\n",
    "        existing_relations = set()\n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            if 'relation' in data:\n",
    "                existing_relations.add(data['relation'])\n",
    "                \n",
    "        # Sample nodes for suggestion exploration\n",
    "        sampled_nodes = np.random.choice(nodes, min(20, len(nodes)), replace=False)\n",
    "        \n",
    "        for node in sampled_nodes:\n",
    "            if len(suggestions) >= max_suggestions:\n",
    "                break\n",
    "                \n",
    "            # Find potential relation targets through graph exploration\n",
    "            potential_targets = self._explore_graph_for_suggestions(node, exploration_depth)\n",
    "            \n",
    "            for target_node, suggested_relation, confidence in potential_targets:\n",
    "                if len(suggestions) >= max_suggestions:\n",
    "                    break\n",
    "                    \n",
    "                if confidence >= confidence_threshold:\n",
    "                    # Check if this relation already exists\n",
    "                    if not self.graph.has_edge(node, target_node):\n",
    "                        # Calculate suggestion priority\n",
    "                        priority = self._calculate_suggestion_priority(\n",
    "                            node, target_node, suggested_relation, confidence, existing_relations\n",
    "                        )\n",
    "                        \n",
    "                        suggestion = {\n",
    "                            'triple': (node, suggested_relation, target_node),\n",
    "                            'confidence': confidence,\n",
    "                            'priority': priority,\n",
    "                            'suggested_weight': min(0.9, confidence + 0.1),  # Convert confidence to weight\n",
    "                            'source': 'graph_exploration',\n",
    "                            'exploration_depth': exploration_depth\n",
    "                        }\n",
    "                        \n",
    "                        suggestions.append(suggestion)\n",
    "                        \n",
    "        # Sort suggestions by priority and return top ones\n",
    "        suggestions.sort(key=lambda x: x['priority'], reverse=True)\n",
    "        return suggestions[:max_suggestions]\n",
    "    \n",
    "    def _explore_graph_for_suggestions(self, start_node, max_depth):\n",
    "        \"\"\"Explore graph to find potential relation suggestions\"\"\"\n",
    "        suggestions = []\n",
    "        visited = {start_node}\n",
    "        \n",
    "        # BFS exploration from start_node\n",
    "        current_level = [start_node]\n",
    "        \n",
    "        for depth in range(max_depth):\n",
    "            next_level = []\n",
    "            \n",
    "            for node in current_level:\n",
    "                # Explore neighbors\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "                    if neighbor not in visited:\n",
    "                        visited.add(neighbor)\n",
    "                        next_level.append(neighbor)\n",
    "                        \n",
    "                        # Suggest potential relations based on path analysis\n",
    "                        relation_suggestions = self._analyze_path_for_relations(start_node, neighbor, depth + 1)\n",
    "                        suggestions.extend(relation_suggestions)\n",
    "                        \n",
    "            current_level = next_level\n",
    "            if not current_level:  # No more nodes to explore\n",
    "                break\n",
    "                \n",
    "        return suggestions\n",
    "    \n",
    "    def _analyze_path_for_relations(self, source, target, path_length):\n",
    "        \"\"\"Analyze potential relations between source and target based on graph patterns\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        # Get relation types from the graph\n",
    "        graph_relations = set()\n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            if 'relation' in data:\n",
    "                graph_relations.add(data['relation'])\n",
    "                \n",
    "        if not graph_relations:\n",
    "            return suggestions\n",
    "            \n",
    "        # Analyze common neighbors for relation inference\n",
    "        source_neighbors = set(self.graph.neighbors(source))\n",
    "        target_neighbors = set(self.graph.neighbors(target))\n",
    "        common_neighbors = source_neighbors.intersection(target_neighbors)\n",
    "        \n",
    "        # Base confidence starts lower for longer paths\n",
    "        base_confidence = max(0.3, 0.8 - (path_length * 0.15))\n",
    "        \n",
    "        # Suggest relations based on common neighbor patterns\n",
    "        for relation in graph_relations:\n",
    "            confidence = base_confidence\n",
    "            \n",
    "            # Boost confidence if there are common neighbors with this relation\n",
    "            relation_boost = 0\n",
    "            for neighbor in common_neighbors:\n",
    "                if self.graph.has_edge(source, neighbor):\n",
    "                    edge_data = self.graph[source][neighbor]\n",
    "                    if edge_data.get('relation') == relation:\n",
    "                        relation_boost += 0.1\n",
    "                if self.graph.has_edge(target, neighbor):\n",
    "                    edge_data = self.graph[target][neighbor]\n",
    "                    if edge_data.get('relation') == relation:\n",
    "                        relation_boost += 0.1\n",
    "                        \n",
    "            confidence += min(0.3, relation_boost)\n",
    "            \n",
    "            # Add some randomness for exploration\n",
    "            confidence += np.random.uniform(-0.05, 0.05)\n",
    "            \n",
    "            if confidence > 0.4:  # Only suggest if reasonably confident\n",
    "                suggestions.append((target, relation, confidence))\n",
    "                \n",
    "        return suggestions\n",
    "    \n",
    "    def _calculate_suggestion_priority(self, source, target, relation, confidence, existing_relations):\n",
    "        \"\"\"Calculate priority score for a relation suggestion\"\"\"\n",
    "        priority = 0.0\n",
    "        \n",
    "        # Base priority from confidence\n",
    "        priority += confidence * self.config.get('suggestion_semantic_weight', 0.6)\n",
    "        \n",
    "        # Novelty bonus for new relation types\n",
    "        if relation not in existing_relations:\n",
    "            priority += self.config.get('suggestion_novelty_weight', 0.4) * 0.5\n",
    "            \n",
    "        # Diversity factor - encourage different relation types\n",
    "        diversity_factor = self.config.get('suggestion_diversity_factor', 0.3)\n",
    "        relation_frequency = sum(1 for _, _, d in self.graph.edges(data=True) \n",
    "                               if d.get('relation') == relation)\n",
    "        total_edges = self.graph.number_of_edges()\n",
    "        \n",
    "        if total_edges > 0:\n",
    "            relation_rarity = 1 - (relation_frequency / total_edges)\n",
    "            priority += diversity_factor * relation_rarity\n",
    "            \n",
    "        # Structural importance - nodes with higher degree get priority\n",
    "        source_degree = self.graph.degree(source)\n",
    "        target_degree = self.graph.degree(target)\n",
    "        degree_factor = min(0.2, (source_degree + target_degree) * 0.01)\n",
    "        priority += degree_factor\n",
    "        \n",
    "        # Add small random component for tie-breaking\n",
    "        priority += np.random.uniform(0, 0.02)\n",
    "        \n",
    "        return max(0.0, min(1.0, priority))\n",
    "    \n",
    "    def process_suggested_relations(self, suggestions):\n",
    "        \"\"\"Process and validate suggested relations\"\"\"\n",
    "        if not suggestions:\n",
    "            return 0\n",
    "            \n",
    "        processed_count = 0\n",
    "        \n",
    "        for suggestion in suggestions:\n",
    "            triple = suggestion['triple']\n",
    "            confidence = suggestion['confidence']\n",
    "            suggested_weight = suggestion['suggested_weight']\n",
    "            \n",
    "            # Track the suggestion\n",
    "            suggestion_key = str(triple)\n",
    "            self.suggested_relations[suggestion_key] = {\n",
    "                'suggestion': suggestion,\n",
    "                'processed': True,\n",
    "                'timestamp': self.training_metrics['iterations_completed']\n",
    "            }\n",
    "            \n",
    "            # Validate the suggested relation\n",
    "            decision, score = self.validate_triple(triple, suggested_weight, is_false=False)\n",
    "            \n",
    "            # Track suggestion outcome\n",
    "            suggestion_record = {\n",
    "                'triple': triple,\n",
    "                'confidence': confidence,\n",
    "                'decision': decision,\n",
    "                'score': score,\n",
    "                'priority': suggestion['priority'],\n",
    "                'source': suggestion['source'],\n",
    "                'iteration': self.training_metrics['iterations_completed'],\n",
    "                'epoch': self.training_metrics['epochs_completed']\n",
    "            }\n",
    "            \n",
    "            self.suggestion_history.append(suggestion_record)\n",
    "            \n",
    "            if decision == 'ACCEPT':\n",
    "                self.suggestions_accepted += 1\n",
    "                self.training_metrics['suggestions_accepted'] += 1\n",
    "                self.add_triple_to_graph(triple, suggested_weight)\n",
    "            elif decision == 'REJECT':\n",
    "                self.suggestions_rejected += 1\n",
    "                self.training_metrics['suggestions_rejected'] += 1\n",
    "                \n",
    "            self.training_metrics['suggestions_generated'] += 1\n",
    "            self.suggestion_scores.append(confidence)\n",
    "            processed_count += 1\n",
    "            \n",
    "        return processed_count\n",
    "    \n",
    "    def update_suggestion_metrics(self):\n",
    "        \"\"\"Update suggestion-related metrics\"\"\"\n",
    "        total_suggestions = self.training_metrics['suggestions_generated']\n",
    "        \n",
    "        if total_suggestions > 0:\n",
    "            # Calculate suggestion accuracy\n",
    "            total_validated = (self.training_metrics['suggestions_accepted'] + \n",
    "                             self.training_metrics['suggestions_rejected'])\n",
    "            if total_validated > 0:\n",
    "                self.training_metrics['suggestion_accuracy'] = (\n",
    "                    self.training_metrics['suggestions_accepted'] / total_validated\n",
    "                )\n",
    "                \n",
    "            # Calculate average suggestion confidence\n",
    "            if self.suggestion_scores:\n",
    "                self.training_metrics['avg_suggestion_confidence'] = np.mean(self.suggestion_scores)\n",
    "                \n",
    "            # Calculate suggestion diversity (unique relation types suggested)\n",
    "            if self.suggestion_history:\n",
    "                suggested_relation_types = set()\n",
    "                for record in self.suggestion_history:\n",
    "                    suggested_relation_types.add(record['triple'][1])\n",
    "                self.training_metrics['suggestion_diversity'] = len(suggested_relation_types)\n",
    "    \n",
    "    def process_pending_relations(self):\n",
    "        \"\"\"Enhanced process relations with prioritization and configurable batch limits\"\"\"\n",
    "        if not self.pending_relations:\n",
    "            return 0\n",
    "            \n",
    "        resolved_relations = []\n",
    "        max_attempts = self.config.get('max_resolution_attempts_per_batch', 50)\n",
    "        top_limit = self.config.get('top_weight_resolution_limit', 100)\n",
    "        \n",
    "        # Filter out epoch-locked relations\n",
    "        available_relations = {\n",
    "            key: data for key, data in self.pending_relations.items() \n",
    "            if not data.get('epoch_locked', False)\n",
    "        }\n",
    "        \n",
    "        if not available_relations:\n",
    "            return 0\n",
    "        \n",
    "        # Sort relations by priority weight (highest first)\n",
    "        sorted_relations = sorted(\n",
    "            available_relations.items(),\n",
    "            key=lambda x: x[1].get('priority_weight', 0.5),\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        # Take only top N highest-weighted pending relations\n",
    "        top_relations = sorted_relations[:top_limit]\n",
    "        \n",
    "        # Process up to max_attempts relations this batch\n",
    "        attempts_this_batch = 0\n",
    "        \n",
    "        for triple_key, relation_data in top_relations:\n",
    "            if attempts_this_batch >= max_attempts:\n",
    "                break\n",
    "                \n",
    "            # Check if this relation has already been attempted 3 times this batch cycle\n",
    "            if self.relation_attempts.get(triple_key, 0) >= 3:\n",
    "                continue\n",
    "                \n",
    "            triple = relation_data['triple']\n",
    "            edge_weight = relation_data['edge_weight']\n",
    "            is_false = relation_data['is_false']\n",
    "            \n",
    "            # Try to resolve the pending relation\n",
    "            decision, score = self.validate_triple(triple, edge_weight, is_false)\n",
    "            attempts_this_batch += 1\n",
    "            \n",
    "            if decision in ['ACCEPT', 'REJECT']:\n",
    "                resolved_relations.append(triple_key)\n",
    "                self.training_metrics['top_weight_resolutions'] += 1\n",
    "                \n",
    "                # Add to graph if accepted\n",
    "                if decision == 'ACCEPT':\n",
    "                    self.add_triple_to_graph(triple, edge_weight)\n",
    "        \n",
    "        # Track resolution attempts per batch\n",
    "        self.training_metrics['resolution_attempts_per_batch'].append(attempts_this_batch)\n",
    "        \n",
    "        return len(resolved_relations)\n",
    "    \n",
    "    def add_triple_to_graph(self, triple, edge_weight=1.0):\n",
    "        \"\"\"Add validated triple to the agent's graph\"\"\"\n",
    "        subj, rel, obj = triple\n",
    "        self.graph.add_edge(subj, obj, relation=rel, weight=edge_weight)\n",
    "    \n",
    "    def train_on_batch(self, triples_batch, edge_weights, false_flags):\n",
    "        \"\"\"Enhanced training with relation suggestions and prioritized pending relation resolution\"\"\"\n",
    "        # Reset attempt counters for new batch cycle\n",
    "        self.relation_attempts = {}\n",
    "        \n",
    "        batch_accuracy = 0\n",
    "        total_decisions = 0\n",
    "        \n",
    "        # First, try to resolve any pending relations from previous batches using prioritization\n",
    "        resolved_count = self.process_pending_relations()\n",
    "        \n",
    "        # === RELATION SUGGESTION PROCESSING ===\n",
    "        # Generate and process relation suggestions if enabled\n",
    "        if self.config.get('enable_relation_suggestions', False):\n",
    "            suggestions = self.generate_relation_suggestions()\n",
    "            if suggestions:\n",
    "                suggestion_count = self.process_suggested_relations(suggestions)\n",
    "                if self.config.get('verbose', False) and suggestion_count > 0:\n",
    "                    print(f\"  {self.agent_id}: Generated {len(suggestions)} suggestions, processed {suggestion_count}\")\n",
    "        \n",
    "        # Process new triples\n",
    "        for triple, weight, is_false in zip(triples_batch, edge_weights, false_flags):\n",
    "            decision, score = self.validate_triple(triple, weight, is_false)\n",
    "            \n",
    "            # Add to graph if accepted immediately\n",
    "            if decision == 'ACCEPT':\n",
    "                self.add_triple_to_graph(triple, weight)\n",
    "            \n",
    "            # Track accuracy only for resolved decisions (ACCEPT/REJECT)\n",
    "            if decision in ['ACCEPT', 'REJECT']:\n",
    "                correct = (decision == 'REJECT') if is_false else (decision == 'ACCEPT')\n",
    "                batch_accuracy += correct\n",
    "                total_decisions += 1\n",
    "            \n",
    "            self.training_metrics['triples_processed'] += 1\n",
    "            if is_false and decision == 'REJECT':\n",
    "                self.training_metrics['false_triples_detected'] += 1\n",
    "        \n",
    "        # Update accuracy based on resolved decisions only\n",
    "        if total_decisions > 0:\n",
    "            self.training_metrics['accuracy'] = batch_accuracy / total_decisions\n",
    "            self.quality_scores.append(self.training_metrics['accuracy'])\n",
    "        else:\n",
    "            # If no decisions were made this batch, maintain previous accuracy\n",
    "            if self.quality_scores:\n",
    "                self.quality_scores.append(self.quality_scores[-1])\n",
    "            else:\n",
    "                self.quality_scores.append(0.0)\n",
    "                \n",
    "        # Update suggestion metrics\n",
    "        self.update_suggestion_metrics()\n",
    "    \n",
    "    def get_resolution_stats(self):\n",
    "        \"\"\"Enhanced statistics about relation resolution including prioritization metrics\"\"\"\n",
    "        total_relations = len(self.relation_review_count)  # Use review count for total seen\n",
    "        pending_count = len(self.pending_relations)\n",
    "        epoch_locked_count = sum(1 for data in self.pending_relations.values() if data.get('epoch_locked', False))\n",
    "        resolved_count = self.training_metrics['relations_resolved']\n",
    "        forced_count = self.training_metrics['forced_decisions']\n",
    "        top_weight_resolutions = self.training_metrics['top_weight_resolutions']\n",
    "        \n",
    "        # Calculate average resolution attempts per batch\n",
    "        avg_attempts_per_batch = 0\n",
    "        if self.training_metrics['resolution_attempts_per_batch']:\n",
    "            avg_attempts_per_batch = np.mean(self.training_metrics['resolution_attempts_per_batch'])\n",
    "        \n",
    "        # Calculate priority weight distribution of pending relations\n",
    "        if self.pending_relations:\n",
    "            priority_weights = [data.get('priority_weight', 0.5) for data in self.pending_relations.values()]\n",
    "            avg_priority_weight = np.mean(priority_weights)\n",
    "            max_priority_weight = np.max(priority_weights)\n",
    "            min_priority_weight = np.min(priority_weights)\n",
    "        else:\n",
    "            avg_priority_weight = 0.0\n",
    "            max_priority_weight = 0.0\n",
    "            min_priority_weight = 0.0\n",
    "        \n",
    "        return {\n",
    "            'total_relations_seen': total_relations,\n",
    "            'relations_resolved': resolved_count,\n",
    "            'relations_pending': pending_count,\n",
    "            'relations_epoch_locked': epoch_locked_count,\n",
    "            'forced_decisions': forced_count,\n",
    "            'top_weight_resolutions': top_weight_resolutions,\n",
    "            'avg_attempts_per_batch': avg_attempts_per_batch,\n",
    "            'avg_priority_weight': avg_priority_weight,\n",
    "            'max_priority_weight': max_priority_weight,\n",
    "            'min_priority_weight': min_priority_weight,\n",
    "            'resolution_rate': resolved_count / total_relations if total_relations > 0 else 0,\n",
    "            'pending_rate': pending_count / total_relations if total_relations > 0 else 0,\n",
    "            'epoch_locked_rate': epoch_locked_count / total_relations if total_relations > 0 else 0,\n",
    "            'forced_rate': forced_count / total_relations if total_relations > 0 else 0,\n",
    "            'top_weight_rate': top_weight_resolutions / resolved_count if resolved_count > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def complete_epoch(self):\n",
    "        \"\"\"Enhanced epoch completion with suggestion tracking reset\"\"\"\n",
    "        self.training_metrics['epochs_completed'] += 1\n",
    "        \n",
    "        # Store epoch-level metrics\n",
    "        stats = self.get_graph_stats()\n",
    "        resolution_stats = self.get_resolution_stats()\n",
    "        \n",
    "        self.training_metrics['epoch_accuracies'].append(self.training_metrics['accuracy'])\n",
    "        self.training_metrics['epoch_nodes'].append(stats['nodes'])\n",
    "        self.training_metrics['epoch_edges'].append(stats['edges'])\n",
    "        \n",
    "        # Log detailed epoch completion information\n",
    "        if self.config.get('verbose', False):\n",
    "            print(f\"\\n--- Agent {self.agent_id} Epoch {self.training_metrics['epochs_completed']} Complete ---\")\n",
    "            print(f\"Accuracy: {self.training_metrics['accuracy']:.3f}\")\n",
    "            print(f\"Graph: {stats['nodes']} nodes, {stats['edges']} edges\")\n",
    "            print(f\"Resolution: {resolution_stats['relations_resolved']} resolved, {resolution_stats['relations_pending']} pending\")\n",
    "            print(f\"Top-weight resolutions: {resolution_stats['top_weight_resolutions']}\")\n",
    "            print(f\"Avg attempts per batch: {resolution_stats['avg_attempts_per_batch']:.1f}\")\n",
    "            \n",
    "            # Log suggestion statistics\n",
    "            if self.config.get('enable_relation_suggestions', False):\n",
    "                print(f\"Suggestions: {self.training_metrics['suggestions_generated']} generated, \"\n",
    "                      f\"{self.training_metrics['suggestions_accepted']} accepted, \"\n",
    "                      f\"{self.training_metrics['suggestions_rejected']} rejected\")\n",
    "                if self.training_metrics['suggestions_generated'] > 0:\n",
    "                    print(f\"Suggestion accuracy: {self.training_metrics['suggestion_accuracy']:.3f}\")\n",
    "                    print(f\"Avg suggestion confidence: {self.training_metrics['avg_suggestion_confidence']:.3f}\")\n",
    "                    print(f\"Suggestion diversity: {self.training_metrics['suggestion_diversity']} relation types\")\n",
    "            \n",
    "            if resolution_stats['relations_pending'] > 0:\n",
    "                print(f\"Priority range: {resolution_stats['min_priority_weight']:.3f} - {resolution_stats['max_priority_weight']:.3f}\")\n",
    "        \n",
    "        # CRITICAL FIX: Reset both attempt counts AND review counts for fresh epoch integration\n",
    "        self.relation_attempts = {}\n",
    "        self.relation_review_count = {}\n",
    "        \n",
    "        # Clear pending relations (fresh start for new epoch)\n",
    "        self.pending_relations = {}\n",
    "        \n",
    "        # === RESET SUGGESTION TRACKING FOR NEW EPOCH ===\n",
    "        self.suggested_relations = {}\n",
    "        # Note: Keep suggestion_history for cross-epoch analysis, but reset per-epoch counters\n",
    "        \n",
    "        # Reset batch-level tracking for new epoch\n",
    "        self.training_metrics['resolution_attempts_per_batch'] = []\n",
    "        \n",
    "    def get_graph_stats(self):\n",
    "        \"\"\"Get comprehensive graph statistics\"\"\"\n",
    "        # Safely compute average clustering\n",
    "        try:\n",
    "            if self.graph.number_of_nodes() > 1 and self.graph.number_of_edges() > 0:\n",
    "                avg_clustering = nx.average_clustering(self.graph.to_undirected())\n",
    "            else:\n",
    "                avg_clustering = 0.0\n",
    "        except Exception:\n",
    "            avg_clustering = 0.0\n",
    "            \n",
    "        return {\n",
    "            'nodes': self.graph.number_of_nodes(),\n",
    "            'edges': self.graph.number_of_edges(),\n",
    "            'density': nx.density(self.graph),\n",
    "            'avg_clustering': avg_clustering,\n",
    "            'connected_components': nx.number_weakly_connected_components(self.graph),\n",
    "            'avg_degree': np.mean([d for n, d in self.graph.degree()]) if self.graph.number_of_nodes() > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def get_epoch_summary(self):\n",
    "        \"\"\"Get summary of training across all epochs including suggestion metrics\"\"\"\n",
    "        resolution_stats = self.get_resolution_stats()\n",
    "        \n",
    "        summary = {\n",
    "            'agent_id': self.agent_id,\n",
    "            'epochs_completed': self.training_metrics['epochs_completed'],\n",
    "            'total_iterations': self.training_metrics['iterations_completed'],\n",
    "            'total_triples_processed': self.training_metrics['triples_processed'],\n",
    "            'epoch_accuracies': self.training_metrics['epoch_accuracies'],\n",
    "            'epoch_nodes': self.training_metrics['epoch_nodes'],\n",
    "            'epoch_edges': self.training_metrics['epoch_edges'],\n",
    "            'final_accuracy': self.training_metrics['accuracy'],\n",
    "            'false_triples_detected': self.training_metrics['false_triples_detected'],\n",
    "            'decision_distribution': self.decision_log.copy(),\n",
    "            'final_graph_stats': self.get_graph_stats(),\n",
    "            'resolution_stats': resolution_stats\n",
    "        }\n",
    "        \n",
    "        # Add suggestion metrics if enabled\n",
    "        if self.config.get('enable_relation_suggestions', False):\n",
    "            summary['suggestion_stats'] = {\n",
    "                'suggestions_generated': self.training_metrics['suggestions_generated'],\n",
    "                'suggestions_accepted': self.training_metrics['suggestions_accepted'],\n",
    "                'suggestions_rejected': self.training_metrics['suggestions_rejected'],\n",
    "                'suggestion_accuracy': self.training_metrics['suggestion_accuracy'],\n",
    "                'avg_suggestion_confidence': self.training_metrics['avg_suggestion_confidence'],\n",
    "                'suggestion_diversity': self.training_metrics['suggestion_diversity'],\n",
    "                'total_suggestions_in_history': len(self.suggestion_history)\n",
    "            }\n",
    "            \n",
    "        return summary\n",
    "\n",
    "print(\"ValidationAgent class defined successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d989c",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 3: FALSE TRIPLE GENERATOR CLASS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454a985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalseTripleGenerator class defined successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FalseTripleGenerator:\n",
    "    \"\"\"Generate realistic false triples from real ConceptNet data\"\"\"\n",
    "    \n",
    "    def __init__(self, real_triples_df):\n",
    "        self.real_triples = real_triples_df\n",
    "        self.subjects = list(set(real_triples_df['subject'].values))\n",
    "        self.relations = list(set(real_triples_df['relation'].values))\n",
    "        self.objects = list(set(real_triples_df['object'].values))\n",
    "        \n",
    "        # Get edge weight distribution for realistic false weights\n",
    "        if 'edge_weight' in real_triples_df.columns:\n",
    "            self.weights = real_triples_df['edge_weight'].values\n",
    "        else:\n",
    "            self.weights = np.ones(len(real_triples_df))  # Default to 1.0\n",
    "        \n",
    "    def generate_false_triple(self):\n",
    "        \"\"\"Generate a false triple by mixing real components\"\"\"\n",
    "        # Strategy 1: Random recombination (70%)\n",
    "        if np.random.random() < 0.7:\n",
    "            subj = np.random.choice(self.subjects)\n",
    "            rel = np.random.choice(self.relations)\n",
    "            obj = np.random.choice(self.objects)\n",
    "            \n",
    "            # Ensure it's not a real triple\n",
    "            attempts = 0\n",
    "            while self._is_real_triple(subj, rel, obj) and attempts < 10:\n",
    "                obj = np.random.choice(self.objects)\n",
    "                attempts += 1\n",
    "                \n",
    "        # Strategy 2: Semantic contradiction (20%)\n",
    "        elif np.random.random() < 0.9:\n",
    "            # Take a real triple and swap subject/object\n",
    "            real_triple = self.real_triples.sample(1).iloc[0]\n",
    "            subj = real_triple['object']\n",
    "            rel = real_triple['relation']\n",
    "            obj = real_triple['subject']\n",
    "            \n",
    "        # Strategy 3: Nonsensical relations (10%)\n",
    "        else:\n",
    "            real_triple = self.real_triples.sample(1).iloc[0]\n",
    "            subj = real_triple['subject']\n",
    "            rel = np.random.choice(self.relations)\n",
    "            obj = real_triple['object']\n",
    "            \n",
    "            # Ensure different relation\n",
    "            attempts = 0\n",
    "            while rel == real_triple['relation'] and attempts < 10:\n",
    "                rel = np.random.choice(self.relations)\n",
    "                attempts += 1\n",
    "        \n",
    "        # Generate a false but realistic edge weight\n",
    "        # False triples tend to have lower weights in practice\n",
    "        false_weight = np.random.choice(self.weights) * np.random.uniform(0.3, 0.8)\n",
    "        false_weight = max(0.1, min(1.0, false_weight))  # Clamp to valid range\n",
    "                \n",
    "        return (subj, rel, obj), false_weight\n",
    "    \n",
    "    def _is_real_triple(self, subj, rel, obj):\n",
    "        \"\"\"Check if a triple exists in real data\"\"\"\n",
    "        return len(self.real_triples[\n",
    "            (self.real_triples['subject'] == subj) &\n",
    "            (self.real_triples['relation'] == rel) &\n",
    "            (self.real_triples['object'] == obj)\n",
    "        ]) > 0\n",
    "    \n",
    "    def inject_false_triples(self, real_batch, real_weights, false_ratio=0.15):\n",
    "        \"\"\"Inject false triples into a batch of real triples\"\"\"\n",
    "        num_false = int(len(real_batch) * false_ratio)\n",
    "        false_triples = []\n",
    "        false_weights = []\n",
    "        false_flags = [False] * len(real_batch)\n",
    "        \n",
    "        # Generate false triples\n",
    "        for _ in range(num_false):\n",
    "            false_triple, false_weight = self.generate_false_triple()\n",
    "            false_triples.append(false_triple)\n",
    "            false_weights.append(false_weight)\n",
    "        \n",
    "        # Combine and shuffle\n",
    "        all_triples = list(real_batch) + false_triples\n",
    "        all_weights = list(real_weights) + false_weights\n",
    "        all_flags = false_flags + [True] * num_false\n",
    "        \n",
    "        # Shuffle together\n",
    "        combined = list(zip(all_triples, all_weights, all_flags))\n",
    "        np.random.shuffle(combined)\n",
    "        triples, weights, flags = zip(*combined)\n",
    "        \n",
    "        return list(triples), list(weights), list(flags)\n",
    "\n",
    "print(\"FalseTripleGenerator class defined successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c65cc5",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 4: DATA LOADING AND PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8f9ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ConceptNet data...\n",
      "Loaded preprocessed data: 1655522 triples\n",
      "Column mapping applied: start_concept -> subject, relation_type -> relation, end_concept -> object\n",
      "Using 50000 triples for experiment\n",
      "Unique subjects: 21409\n",
      "Unique relations: 46\n",
      "Unique objects: 38234\n",
      "Edge weight distribution:\n",
      "  Mean: 0.941\n",
      "  Range: [0.1, 11.6]\n",
      "  Top weights: {1.0: np.int64(39379), 0.5: np.int64(2714), 0.25: np.int64(1415), 2.0: np.int64(1228), 2.828: np.int64(198)}\n",
      "False triple generator initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading ConceptNet data...\")\n",
    "\n",
    "try:\n",
    "    # Try loading preprocessed parquet file first\n",
    "    conceptnet_file = DATA_PATH / 'conceptnet_en_processed_for_graph.parquet.gzip'\n",
    "    if conceptnet_file.exists():\n",
    "        df_raw = pd.read_parquet(conceptnet_file)\n",
    "        print(f\"Loaded preprocessed data: {len(df_raw)} triples\")\n",
    "        \n",
    "        # Map columns to expected format: relation_type, start_concept, end_concept, edge_weight\n",
    "        if 'relation_type' in df_raw.columns and 'start_concept' in df_raw.columns:\n",
    "            df = df_raw.rename(columns={\n",
    "                'start_concept': 'subject',\n",
    "                'relation_type': 'relation', \n",
    "                'end_concept': 'object'\n",
    "            }).copy()\n",
    "            print(\"Column mapping applied: start_concept -> subject, relation_type -> relation, end_concept -> object\")\n",
    "        else:\n",
    "            # Fallback column mapping if different structure\n",
    "            df = df_raw.copy()\n",
    "            if df.shape[1] >= 3:\n",
    "                df.columns = ['subject', 'relation', 'object'] + list(df.columns[3:])\n",
    "    else:\n",
    "        # Fallback to CSV\n",
    "        conceptnet_file = DATA_PATH / 'conceptnet_en_triples.csv'\n",
    "        df_raw = pd.read_csv(conceptnet_file)\n",
    "        print(f\"Loaded CSV data: {len(df_raw)} triples\")\n",
    "        \n",
    "        # Map columns to expected format\n",
    "        if 'relation_type' in df_raw.columns and 'start_concept' in df_raw.columns:\n",
    "            df = df_raw.rename(columns={\n",
    "                'start_concept': 'subject',\n",
    "                'relation_type': 'relation',\n",
    "                'end_concept': 'object'\n",
    "            }).copy()\n",
    "        else:\n",
    "            df = df_raw.copy()\n",
    "            if 'subject' not in df.columns:\n",
    "                # Assume first three columns are subject, relation, object\n",
    "                df.columns = ['subject', 'relation', 'object'] + list(df.columns[3:])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Create sample data for testing using realistic ConceptNet relations\n",
    "    print(\"Creating sample data for testing...\")\n",
    "    df = pd.DataFrame({\n",
    "        'subject': ['cat', 'dog', 'bird', 'fish', 'tree', 'happy', 'run', 'blue'] * 625,\n",
    "        'relation': ['IsA', 'HasProperty', 'RelatedTo', 'CapableOf', 'AtLocation', 'FormOf', 'DerivedFrom', 'Synonym'] * 625,\n",
    "        'object': ['animal', 'pet', 'living_thing', 'water', 'forest', 'emotion', 'move', 'color'] * 625,\n",
    "        'edge_weight': np.random.choice([0.5, 0.7, 1.0], size=5000, p=[0.1, 0.2, 0.7])  # Realistic weight distribution\n",
    "    })\n",
    "\n",
    "# Sample data for experiment\n",
    "\n",
    "def ensure_all_nodes_connected(df, sample_size):\n",
    "    \"\"\"\n",
    "    Ensure every subject and object in the sample is connected to at least one other node.\n",
    "    \"\"\"\n",
    "    # Start with a random sample\n",
    "    if len(df) <= sample_size:\n",
    "        sample = df.copy()\n",
    "    else:\n",
    "        sample = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Build undirected graph for connectivity check\n",
    "    G = nx.from_pandas_edgelist(sample, 'subject', 'object', create_using=nx.Graph())\n",
    "\n",
    "    # Find isolated nodes (degree 0)\n",
    "    all_nodes = set(sample['subject']).union(set(sample['object']))\n",
    "    node_degrees = dict(G.degree(all_nodes))\n",
    "    isolated_nodes = [node for node, deg in node_degrees.items() if deg == 0]\n",
    "\n",
    "    # For each isolated node, try to add a triple from df that connects it to the sample\n",
    "    for node in isolated_nodes:\n",
    "        # Find triples in df (not already in sample) where node is subject or object\n",
    "        candidates = df[\n",
    "            ((df['subject'] == node) | (df['object'] == node)) &\n",
    "            ~df.index.isin(sample.index)\n",
    "        ]\n",
    "        # Prefer triples that connect to an already-included node\n",
    "        candidates = candidates[\n",
    "            (candidates['subject'].isin(all_nodes)) | (candidates['object'].isin(all_nodes))\n",
    "        ]\n",
    "        if not candidates.empty:\n",
    "            # Add the first candidate triple\n",
    "            sample = pd.concat([sample, candidates.iloc[[0]]], ignore_index=True)\n",
    "            # Update graph and node set\n",
    "            G.add_edge(candidates.iloc[0]['subject'], candidates.iloc[0]['object'])\n",
    "            all_nodes.add(candidates.iloc[0]['subject'])\n",
    "            all_nodes.add(candidates.iloc[0]['object'])\n",
    "\n",
    "    # Remove any remaining isolated nodes (if no connecting triple exists)\n",
    "    G = nx.from_pandas_edgelist(sample, 'subject', 'object', create_using=nx.Graph())\n",
    "    node_degrees = dict(G.degree(all_nodes))\n",
    "    still_isolated = [node for node, deg in node_degrees.items() if deg == 0]\n",
    "    if still_isolated:\n",
    "        sample = sample[\n",
    "            ~sample['subject'].isin(still_isolated) &\n",
    "            ~sample['object'].isin(still_isolated)\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "    # If sample is now larger than sample_size, downsample\n",
    "    if len(sample) > sample_size:\n",
    "        sample = sample.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return sample\n",
    "\n",
    "if len(df) > CONFIG['sample_size']:\n",
    "    df_sample = ensure_all_nodes_connected(df, CONFIG['sample_size'])\n",
    "else:\n",
    "    df_sample = df.copy()\n",
    "\n",
    "print(f\"Using {len(df_sample)} triples for experiment\")\n",
    "print(f\"Unique subjects: {df_sample['subject'].nunique()}\")\n",
    "print(f\"Unique relations: {df_sample['relation'].nunique()}\")\n",
    "print(f\"Unique objects: {df_sample['object'].nunique()}\")\n",
    "\n",
    "# Show edge weight distribution if available\n",
    "if 'edge_weight' in df_sample.columns:\n",
    "    print(f\"Edge weight distribution:\")\n",
    "    print(f\"  Mean: {df_sample['edge_weight'].mean():.3f}\")\n",
    "    print(f\"  Range: [{df_sample['edge_weight'].min():.1f}, {df_sample['edge_weight'].max():.1f}]\")\n",
    "    weight_counts = df_sample['edge_weight'].value_counts().head()\n",
    "    print(f\"  Top weights: {dict(weight_counts)}\")\n",
    "\n",
    "# Create false triple generator\n",
    "false_generator = FalseTripleGenerator(df_sample)\n",
    "print(\"False triple generator initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c9a530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "relation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "object",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "edge_weight",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7289eb4a-53ca-46f3-a451-442d08325ae1",
       "rows": [
        [
         "728667",
         "FormOf",
         "v",
         "swinck",
         "1.0"
        ],
        [
         "366573",
         "DerivedFrom",
         "superviolent",
         "violent",
         "1.0"
        ],
        [
         "904532",
         "IsA",
         "purple_sand_tilefish",
         "n",
         "1.0"
        ],
        [
         "566489",
         "FormOf",
         "n",
         "febricity",
         "1.0"
        ],
        [
         "893824",
         "IsA",
         "international_unit_of_measure",
         "n",
         "1.0"
        ],
        [
         "102382",
         "DerivedFrom",
         "antidiversification",
         "diversification",
         "1.0"
        ],
        [
         "1055210",
         "RelatedTo",
         "canoe",
         "paddled_boat",
         "0.221"
        ],
        [
         "1229076",
         "RelatedTo",
         "in_event_of",
         "in_case_of",
         "1.0"
        ],
        [
         "1456996",
         "RelatedTo",
         "n",
         "twistification",
         "1.0"
        ],
        [
         "1640026",
         "UsedFor",
         "telephone_book",
         "look_up_telephone_number",
         "2.0"
        ],
        [
         "424586",
         "EtymologicallyDerivedFrom",
         "flat",
         "flat",
         "1.0"
        ],
        [
         "801541",
         "HasPrerequisite",
         "determining_truth",
         "knowing_facts",
         "1.0"
        ],
        [
         "719643",
         "FormOf",
         "n",
         "stake_boat",
         "1.0"
        ],
        [
         "1286837",
         "RelatedTo",
         "mole",
         "facial_defect",
         "0.17"
        ],
        [
         "1030022",
         "RelatedTo",
         "a",
         "blit",
         "1.0"
        ],
        [
         "1273161",
         "RelatedTo",
         "r",
         "masoretic",
         "1.0"
        ],
        [
         "452707",
         "EtymologicallyRelatedTo",
         "lickerous",
         "likerous",
         "0.25"
        ],
        [
         "1592937",
         "Synonym",
         "a",
         "teentsy",
         "1.0"
        ],
        [
         "329744",
         "DerivedFrom",
         "reticuli",
         "n",
         "1.0"
        ],
        [
         "279654",
         "DerivedFrom",
         "nonthinker",
         "thinker",
         "1.0"
        ],
        [
         "680134",
         "FormOf",
         "n",
         "pseudodisaccharide",
         "1.0"
        ],
        [
         "1517492",
         "Synonym",
         "n",
         "load",
         "1.0"
        ],
        [
         "1435084",
         "RelatedTo",
         "table",
         "eating_at",
         "0.439"
        ],
        [
         "421134",
         "DistinctFrom",
         "plant",
         "flower",
         "0.168"
        ],
        [
         "326659",
         "DerivedFrom",
         "regioisomer",
         "isomer",
         "1.0"
        ],
        [
         "85432",
         "CausesDesire",
         "confusion",
         "contemplate",
         "2.828"
        ],
        [
         "476735",
         "FormOf",
         "n",
         "accessorial_service",
         "1.0"
        ],
        [
         "1559008",
         "Synonym",
         "en_1",
         "lumpen",
         "1.0"
        ],
        [
         "832148",
         "HasSubevent",
         "committing_perjury",
         "tell_lie",
         "2.828"
        ],
        [
         "1476378",
         "RelatedTo",
         "n",
         "terminate_with_extreme_prejudice",
         "1.0"
        ],
        [
         "1513640",
         "Synonym",
         "n",
         "bcnf",
         "1.0"
        ],
        [
         "153759",
         "DerivedFrom",
         "crystallographically",
         "crystallographic",
         "1.0"
        ],
        [
         "1160219",
         "RelatedTo",
         "eye",
         "face_part",
         "3.123"
        ],
        [
         "168930",
         "DerivedFrom",
         "doubloonie",
         "loonie",
         "1.0"
        ],
        [
         "1653936",
         "language",
         "quora",
         "english_language",
         "0.5"
        ],
        [
         "337277",
         "DerivedFrom",
         "scholaress",
         "scholar",
         "1.0"
        ],
        [
         "618570",
         "FormOf",
         "n",
         "lessener",
         "1.0"
        ],
        [
         "854569",
         "InstanceOf",
         "east_india_company",
         "joint_stock_company",
         "0.5"
        ],
        [
         "1627459",
         "UsedFor",
         "mast",
         "mounting_antenna",
         "1.0"
        ],
        [
         "329581",
         "DerivedFrom",
         "resurrection_man",
         "n",
         "1.0"
        ],
        [
         "118336",
         "DerivedFrom",
         "bewailer",
         "v",
         "1.0"
        ],
        [
         "1204671",
         "RelatedTo",
         "r",
         "consecutively",
         "1.0"
        ],
        [
         "1108758",
         "RelatedTo",
         "n",
         "cyclosystemate",
         "1.0"
        ],
        [
         "1629379",
         "UsedFor",
         "painting",
         "changing_textures",
         "1.0"
        ],
        [
         "427808",
         "EtymologicallyDerivedFrom",
         "row",
         "rowen",
         "1.0"
        ],
        [
         "1319156",
         "RelatedTo",
         "r",
         "stomach",
         "1.0"
        ],
        [
         "60596",
         "CapableOf",
         "person",
         "promise_to_pay_on_time",
         "1.0"
        ],
        [
         "465910",
         "EtymologicallyRelatedTo",
         "sometime",
         "sume_time",
         "0.25"
        ],
        [
         "394311",
         "DerivedFrom",
         "unnice",
         "nice",
         "1.0"
        ],
        [
         "1471903",
         "RelatedTo",
         "waltz",
         "waltzer",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 50000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>edge_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>728667</th>\n",
       "      <td>FormOf</td>\n",
       "      <td>v</td>\n",
       "      <td>swinck</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366573</th>\n",
       "      <td>DerivedFrom</td>\n",
       "      <td>superviolent</td>\n",
       "      <td>violent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904532</th>\n",
       "      <td>IsA</td>\n",
       "      <td>purple_sand_tilefish</td>\n",
       "      <td>n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566489</th>\n",
       "      <td>FormOf</td>\n",
       "      <td>n</td>\n",
       "      <td>febricity</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893824</th>\n",
       "      <td>IsA</td>\n",
       "      <td>international_unit_of_measure</td>\n",
       "      <td>n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391575</th>\n",
       "      <td>RelatedTo</td>\n",
       "      <td>en_2</td>\n",
       "      <td>escapade</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668416</th>\n",
       "      <td>FormOf</td>\n",
       "      <td>n</td>\n",
       "      <td>pigeonhole_principle</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209303</th>\n",
       "      <td>RelatedTo</td>\n",
       "      <td>n</td>\n",
       "      <td>hebetate</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725880</th>\n",
       "      <td>FormOf</td>\n",
       "      <td>n</td>\n",
       "      <td>sulkiness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257023</th>\n",
       "      <td>DerivedFrom</td>\n",
       "      <td>misbefall</td>\n",
       "      <td>befall</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            relation                        subject                object  \\\n",
       "728667        FormOf                              v                swinck   \n",
       "366573   DerivedFrom                   superviolent               violent   \n",
       "904532           IsA           purple_sand_tilefish                     n   \n",
       "566489        FormOf                              n             febricity   \n",
       "893824           IsA  international_unit_of_measure                     n   \n",
       "...              ...                            ...                   ...   \n",
       "1391575    RelatedTo                           en_2              escapade   \n",
       "668416        FormOf                              n  pigeonhole_principle   \n",
       "1209303    RelatedTo                              n              hebetate   \n",
       "725880        FormOf                              n             sulkiness   \n",
       "257023   DerivedFrom                      misbefall                befall   \n",
       "\n",
       "         edge_weight  \n",
       "728667           1.0  \n",
       "366573           1.0  \n",
       "904532           1.0  \n",
       "566489           1.0  \n",
       "893824           1.0  \n",
       "...              ...  \n",
       "1391575          1.0  \n",
       "668416           1.0  \n",
       "1209303          2.0  \n",
       "725880           1.0  \n",
       "257023           1.0  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0bb37",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 5: AGENT INITIALIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51136bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nInitializing {CONFIG['num_agents']} validation agents...\")\n",
    "\n",
    "agents = []\n",
    "for i in range(CONFIG['num_agents']):\n",
    "    # Assign a unique random seed to each agent\n",
    "    agent_config = CONFIG.copy()\n",
    "    agent_config['agent_seed'] = int(time.time() * 1000) % (2**32) + i * 1000\n",
    "    agents.append(ValidationAgent(f\"Agent_{i+1}\", agent_config))\n",
    "    print(f\"  Agent {i+1} initialized with seed {agent_config['agent_seed']}\")\n",
    "\n",
    "print(f\"\\nAll {len(agents)} agents ready for training\")\n",
    "print(\"Agent configurations:\")\n",
    "for agent in agents:\n",
    "    print(f\"  {agent.agent_id}: Graph nodes={agent.graph.number_of_nodes()}, edges={agent.graph.number_of_edges()}\")\n",
    "\n",
    "# Calculate all unique subjects and objects in the dataset\n",
    "all_subjects = set(df_sample['subject'].unique())\n",
    "all_objects = set(df_sample['object'].unique())\n",
    "all_entities = all_subjects | all_objects\n",
    "print(f\"\\nTotal unique subjects and objects: {len(all_entities):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12cbdb",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 6: ADAPTIVE TRAINING SYSTEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe08ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_entity_coverage(agent_graph, all_entities):\n",
    "    \"\"\"Calculate entity coverage for an agent\"\"\"\n",
    "    agent_nodes = set(agent_graph.nodes())\n",
    "    return len(agent_nodes & all_entities) / len(all_entities)\n",
    "\n",
    "def adaptive_training_system(agents, df_sample, false_generator, all_entities, config):\n",
    "    \"\"\"\n",
    "    Intelligent training system that tries coverage-based training first,\n",
    "    then falls back to epoch-based training if needed.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚀 STARTING ADAPTIVE MULTI-AGENT TRAINING SYSTEM\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    training_history = []\n",
    "    training_start_time = time.time()\n",
    "    training_mode = \"DETERMINING\"\n",
    "    \n",
    "    # Configuration\n",
    "    target_coverage = config['target_coverage']\n",
    "    timeout_minutes = config['coverage_timeout_minutes']\n",
    "    max_coverage_iterations = config['coverage_max_iterations']\n",
    "    check_freq = config['coverage_check_frequency']\n",
    "    progress_threshold = config['coverage_progress_threshold']\n",
    "    \n",
    "    print(f\"🎯 Target Coverage: {target_coverage*100:.1f}%\")\n",
    "    print(f\"⏰ Coverage Timeout: {timeout_minutes} minutes\")\n",
    "    print(f\"🔄 Max Coverage Iterations: {max_coverage_iterations}\")\n",
    "    print(f\"📊 Adaptive Mode: {'ENABLED' if config['adaptive_training_mode'] else 'DISABLED'}\")\n",
    "    \n",
    "    # === PHASE 1: TRY COVERAGE-BASED TRAINING ===\n",
    "    if config['adaptive_training_mode'] and config['coverage_based_training']:\n",
    "        print(f\"\\n🎯 PHASE 1: ATTEMPTING COVERAGE-BASED CONTINUOUS TRAINING\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        coverage_reached = [False] * len(agents)\n",
    "        coverage_start_time = time.time()\n",
    "        timeout_time = coverage_start_time + (timeout_minutes * 60)\n",
    "        \n",
    "        # Track coverage progress for stagnation detection\n",
    "        coverage_history = {agent.agent_id: [] for agent in agents}\n",
    "        last_progress_check = 0\n",
    "        \n",
    "        for iteration in range(max_coverage_iterations):\n",
    "            # Check timeout\n",
    "            if time.time() > timeout_time:\n",
    "                print(f\"⏰ TIMEOUT: Coverage-based training exceeded {timeout_minutes} minutes\")\n",
    "                break\n",
    "            \n",
    "            print(f\"\\n📍 Coverage Iteration {iteration + 1}/{max_coverage_iterations}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Train each agent\n",
    "            iteration_results = []\n",
    "            for agent in agents:\n",
    "                # Unique seed for reproducibility\n",
    "                np.random.seed(agent.config.get('agent_seed', 42) + iteration * 1000)\n",
    "                random.seed(agent.config.get('agent_seed', 42) + iteration * 1000)\n",
    "                \n",
    "                # Sample batch\n",
    "                batch_data = df_sample.sample(n=min(config['batch_size'], len(df_sample)), replace=True)\n",
    "                real_triples = [(row['subject'], row['relation'], row['object']) \n",
    "                               for _, row in batch_data.iterrows()]\n",
    "                real_weights = batch_data.get('edge_weight', pd.Series([1.0] * len(batch_data))).values\n",
    "                \n",
    "                # Inject false triples\n",
    "                mixed_triples, mixed_weights, truth_flags = false_generator.inject_false_triples(\n",
    "                    real_triples, real_weights, config['false_triple_ratio']\n",
    "                )\n",
    "                \n",
    "                # Train agent\n",
    "                agent.train_on_batch(mixed_triples, mixed_weights, truth_flags)\n",
    "                agent.training_metrics['iterations_completed'] = iteration + 1\n",
    "                stats = agent.get_graph_stats()\n",
    "                accuracy = agent.training_metrics['accuracy']\n",
    "                \n",
    "                iteration_results.append({\n",
    "                    'agent_id': agent.agent_id,\n",
    "                    'mode': 'COVERAGE_BASED',\n",
    "                    'iteration': iteration + 1,\n",
    "                    'accuracy': accuracy,\n",
    "                    'graph_nodes': stats['nodes'],\n",
    "                    'graph_edges': stats['edges'],\n",
    "                    'graph_density': stats['density'],\n",
    "                    'decisions': agent.decision_log.copy()\n",
    "                })\n",
    "                \n",
    "                if config['verbose'] and iteration % 5 == 0:\n",
    "                    print(f\"    {agent.agent_id}: Acc={accuracy:.3f}, Nodes={stats['nodes']}, Edges={stats['edges']}\")\n",
    "            \n",
    "            # Check coverage every N iterations\n",
    "            if (iteration + 1) % check_freq == 0:\n",
    "                print(f\"\\n📊 COVERAGE CHECK (Iteration {iteration + 1}):\")\n",
    "                current_coverages = []\n",
    "                \n",
    "                for idx, agent in enumerate(agents):\n",
    "                    coverage = get_entity_coverage(agent.graph, all_entities)\n",
    "                    coverage_history[agent.agent_id].append(coverage)\n",
    "                    current_coverages.append(coverage)\n",
    "                    \n",
    "                    if not coverage_reached[idx] and coverage >= target_coverage:\n",
    "                        print(f\"🎉 {agent.agent_id} reached {coverage*100:.1f}% coverage!\")\n",
    "                        coverage_reached[idx] = True\n",
    "                    else:\n",
    "                        print(f\"   {agent.agent_id}: {coverage*100:.1f}% coverage\")\n",
    "                \n",
    "                # Check if all agents reached target\n",
    "                if all(coverage_reached):\n",
    "                    elapsed_time = time.time() - coverage_start_time\n",
    "                    print(f\"\\n🏆 SUCCESS! All agents reached {target_coverage*100:.1f}% coverage in {elapsed_time/60:.1f} minutes\")\n",
    "                    training_mode = \"COVERAGE_SUCCESS\"\n",
    "                    training_history.extend(iteration_results)\n",
    "                    break\n",
    "                \n",
    "                # Check for stagnation (no progress in coverage)\n",
    "                if iteration > 50 and (iteration - last_progress_check) >= 50:\n",
    "                    progress_detected = False\n",
    "                    for agent_id, hist in coverage_history.items():\n",
    "                        if len(hist) >= 2:\n",
    "                            recent_progress = hist[-1] - hist[-6] if len(hist) >= 6 else hist[-1] - hist[0]\n",
    "                            if recent_progress >= progress_threshold:\n",
    "                                progress_detected = True\n",
    "                                break\n",
    "                    \n",
    "                    if not progress_detected:\n",
    "                        avg_coverage = np.mean(current_coverages)\n",
    "                        print(f\"⚠️  STAGNATION: No significant progress detected (avg coverage: {avg_coverage*100:.1f}%)\")\n",
    "                        if avg_coverage < 0.5:  # Very low coverage\n",
    "                            print(\"💔 Coverage-based training appears ineffective - will fallback to epochs\")\n",
    "                            break\n",
    "                    \n",
    "                    last_progress_check = iteration\n",
    "            \n",
    "            training_history.extend(iteration_results)\n",
    "        \n",
    "        # Assess coverage-based training results\n",
    "        if not all(coverage_reached):\n",
    "            final_coverages = [get_entity_coverage(agent.graph, all_entities) for agent in agents]\n",
    "            avg_coverage = np.mean(final_coverages)\n",
    "            elapsed_time = time.time() - coverage_start_time\n",
    "            \n",
    "            print(f\"\\n📊 COVERAGE-BASED TRAINING RESULTS:\")\n",
    "            print(f\"   Average Coverage: {avg_coverage*100:.1f}%\")\n",
    "            print(f\"   Agents at Target: {sum(coverage_reached)}/{len(agents)}\")\n",
    "            print(f\"   Time Elapsed: {elapsed_time/60:.1f} minutes\")\n",
    "            \n",
    "            if not config['fallback_to_epochs']:\n",
    "                print(\"🛑 Fallback disabled - stopping training\")\n",
    "                training_mode = \"COVERAGE_INCOMPLETE\"\n",
    "            else:\n",
    "                print(\"🔄 Proceeding to epoch-based training fallback\")\n",
    "                training_mode = \"FALLBACK_TO_EPOCHS\"\n",
    "        else:\n",
    "            training_mode = \"COVERAGE_SUCCESS\"\n",
    "    else:\n",
    "        print(f\"⏩ SKIPPING coverage-based training (disabled in config)\")\n",
    "        training_mode = \"EPOCH_BASED_ONLY\"\n",
    "    \n",
    "    # === PHASE 2: EPOCH-BASED TRAINING (FALLBACK OR PRIMARY) ===\n",
    "    if training_mode in [\"FALLBACK_TO_EPOCHS\", \"EPOCH_BASED_ONLY\"]:\n",
    "        print(f\"\\n🏛️ PHASE 2: EPOCH-BASED TRAINING\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        if training_mode == \"FALLBACK_TO_EPOCHS\":\n",
    "            print(\"🔄 Coverage-based training incomplete - using epoch-based as fallback\")\n",
    "        else:\n",
    "            print(\"📚 Using traditional epoch-based training as primary method\")\n",
    "        \n",
    "        # Traditional epoch-based training\n",
    "        max_epochs = config.get('num_epochs', 5)\n",
    "        max_iterations = config.get('max_iterations', 150)\n",
    "        batch_size = config['batch_size']\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(f\"\\n📖 EPOCH {epoch+1}/{max_epochs}\")\n",
    "            print(\"=\" * 30)\n",
    "            \n",
    "            for iteration in range(max_iterations):\n",
    "                if config['epoch_verbose'] and iteration % 20 == 0:\n",
    "                    print(f\"   Iteration {iteration + 1}/{max_iterations}\")\n",
    "                    \n",
    "                    # Show resolution summary every 50 iterations  \n",
    "                    if iteration % 50 == 0:\n",
    "                        print(\"   Resolution Status:\")\n",
    "                        for agent in agents:\n",
    "                            res_stats = agent.get_resolution_stats()\n",
    "                            print(f\"     {agent.agent_id}: {res_stats['resolution_rate']:.1%} resolved, \" +\n",
    "                                  f\"{res_stats['pending_rate']:.1%} pending, \" +\n",
    "                                  f\"{res_stats['forced_rate']:.1%} forced\")\n",
    "                \n",
    "                # Each agent trains independently\n",
    "                iteration_results = []\n",
    "                for agent in agents:\n",
    "                    # Unique seed\n",
    "                    np.random.seed(agent.config.get('agent_seed', 42) + epoch * 1000 + iteration)\n",
    "                    random.seed(agent.config.get('agent_seed', 42) + epoch * 1000 + iteration)\n",
    "                    \n",
    "                    # Sample and train\n",
    "                    batch_data = df_sample.sample(n=min(batch_size, len(df_sample)), replace=True)\n",
    "                    real_triples = [(row['subject'], row['relation'], row['object']) \n",
    "                                   for _, row in batch_data.iterrows()]\n",
    "                    real_weights = batch_data.get('edge_weight', pd.Series([1.0] * len(batch_data))).values\n",
    "                    \n",
    "                    mixed_triples, mixed_weights, truth_flags = false_generator.inject_false_triples(\n",
    "                        real_triples, real_weights, config['false_triple_ratio']\n",
    "                    )\n",
    "                    \n",
    "                    agent.train_on_batch(mixed_triples, mixed_weights, truth_flags)\n",
    "                    agent.training_metrics['iterations_completed'] = iteration + 1\n",
    "                    stats = agent.get_graph_stats()\n",
    "                    accuracy = agent.training_metrics['accuracy']\n",
    "                    \n",
    "                    iteration_results.append({\n",
    "                        'agent_id': agent.agent_id,\n",
    "                        'mode': 'EPOCH_BASED',\n",
    "                        'epoch': epoch + 1,\n",
    "                        'iteration': iteration + 1,\n",
    "                        'accuracy': accuracy,\n",
    "                        'graph_nodes': stats['nodes'],\n",
    "                        'graph_edges': stats['edges'],\n",
    "                        'graph_density': stats['density'],\n",
    "                        'decisions': agent.decision_log.copy()\n",
    "                    })\n",
    "                \n",
    "                training_history.extend(iteration_results)\n",
    "                \n",
    "                # Verbose output\n",
    "                if config['verbose'] and iteration % 30 == 0:\n",
    "                    for agent in agents:\n",
    "                        stats = agent.get_graph_stats()\n",
    "                        accuracy = agent.training_metrics['accuracy']\n",
    "                        resolution_stats = agent.get_resolution_stats()\n",
    "                        print(f\"      {agent.agent_id}: Acc={accuracy:.3f}, Nodes={stats['nodes']}, Edges={stats['edges']}\")\n",
    "                        print(f\"        Resolved={resolution_stats['relations_resolved']}, \" +\n",
    "                              f\"Pending={resolution_stats['relations_pending']}, \" +\n",
    "                              f\"Forced={resolution_stats['forced_decisions']}, \" +\n",
    "                              f\"Resolution Rate={resolution_stats['resolution_rate']:.2f}\")\n",
    "            \n",
    "            # Complete epoch for all agents\n",
    "            for agent in agents:\n",
    "                agent.complete_epoch()\n",
    "        \n",
    "        training_mode = \"EPOCH_BASED_COMPLETE\"\n",
    "    \n",
    "    # === FINAL RESOLUTION PASS ===\n",
    "    print(f\"\\n🔍 FINAL RESOLUTION PASS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_pending_before = sum(len(agent.pending_relations) for agent in agents)\n",
    "    print(f\"Total pending relations before final pass: {total_pending_before}\")\n",
    "    \n",
    "    if total_pending_before > 0:\n",
    "        print(\"Forcing resolution of all pending relations...\")\n",
    "        \n",
    "        for agent in agents:\n",
    "            pending_count = len(agent.pending_relations)\n",
    "            if pending_count > 0:\n",
    "                print(f\"  {agent.agent_id}: Resolving {pending_count} pending relations\")\n",
    "                \n",
    "                # Force resolution of all pending relations\n",
    "                pending_copy = list(agent.pending_relations.items())\n",
    "                for triple_key, relation_data in pending_copy:\n",
    "                    triple = relation_data['triple']\n",
    "                    edge_weight = relation_data['edge_weight']\n",
    "                    is_false = relation_data['is_false']\n",
    "                    \n",
    "                    # Force decision on this relation\n",
    "                    decision, score = agent.validate_triple(triple, edge_weight, is_false, force_decision=True)\n",
    "                    \n",
    "                    if decision == 'ACCEPT':\n",
    "                        agent.add_triple_to_graph(triple, edge_weight)\n",
    "        \n",
    "        total_pending_after = sum(len(agent.pending_relations) for agent in agents)\n",
    "        print(f\"Total pending relations after final pass: {total_pending_after}\")\n",
    "        \n",
    "        if total_pending_after == 0:\n",
    "            print(\"✅ All relations successfully resolved!\")\n",
    "        else:\n",
    "            print(f\"⚠️  {total_pending_after} relations still pending (should be 0)\")\n",
    "    \n",
    "    # === TRAINING SUMMARY ===\n",
    "    total_time = time.time() - training_start_time\n",
    "    print(f\"\\n🎉 ADAPTIVE TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"🎯 Final Training Mode: {training_mode}\")\n",
    "    print(f\"⏱️  Total Training Time: {total_time/60:.1f} minutes\")\n",
    "    print(f\"📊 Total Training Records: {len(training_history)}\")\n",
    "    \n",
    "    # Final coverage check\n",
    "    print(f\"\\n📈 FINAL COVERAGE ANALYSIS:\")\n",
    "    for agent in agents:\n",
    "        coverage = get_entity_coverage(agent.graph, all_entities)\n",
    "        stats = agent.get_graph_stats()\n",
    "        print(f\"   {agent.agent_id}: {coverage*100:.1f}% coverage, {stats['nodes']} nodes, {stats['edges']} edges\")\n",
    "    \n",
    "    return training_history, training_mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e63ce8",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 7: EXECUTE TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"🎯 Initializing Adaptive Training System...\")\n",
    "required_coverage = CONFIG['target_coverage']  # Use config value\n",
    "\n",
    "training_history, final_training_mode = adaptive_training_system(\n",
    "    agents=agents,\n",
    "    df_sample=df_sample, \n",
    "    false_generator=false_generator,\n",
    "    all_entities=all_entities,\n",
    "    config=CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde133b",
   "metadata": {},
   "source": [
    "# SECTION 8: SIMILARITY ANALYSIS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74936fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_jaccard_similarity(graph1, graph2):\n",
    "    \"\"\"Calculate Jaccard similarity between two graphs\"\"\"\n",
    "    edges1 = set(graph1.edges())\n",
    "    edges2 = set(graph2.edges())\n",
    "    \n",
    "    intersection = len(edges1.intersection(edges2))\n",
    "    union = len(edges1.union(edges2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def calculate_weighted_jaccard_similarity(graph1, graph2):\n",
    "    \"\"\"Calculate weighted Jaccard similarity considering edge weights\"\"\"\n",
    "    # Get all edges from both graphs\n",
    "    all_edges = set(graph1.edges()) | set(graph2.edges())\n",
    "    \n",
    "    if not all_edges:\n",
    "        return 0\n",
    "    \n",
    "    intersection_weight = 0\n",
    "    union_weight = 0\n",
    "    \n",
    "    for edge in all_edges:\n",
    "        weight1 = graph1[edge[0]][edge[1]].get('weight', 0) if graph1.has_edge(*edge) else 0\n",
    "        weight2 = graph2[edge[0]][edge[1]].get('weight', 0) if graph2.has_edge(*edge) else 0\n",
    "        \n",
    "        intersection_weight += min(weight1, weight2)\n",
    "        union_weight += max(weight1, weight2)\n",
    "    \n",
    "    return intersection_weight / union_weight if union_weight > 0 else 0\n",
    "\n",
    "def calculate_node_overlap(graph1, graph2):\n",
    "    \"\"\"Calculate node overlap between two graphs\"\"\"\n",
    "    nodes1 = set(graph1.nodes())\n",
    "    nodes2 = set(graph2.nodes())\n",
    "    \n",
    "    intersection = len(nodes1.intersection(nodes2))\n",
    "    union = len(nodes1.union(nodes2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def calculate_structural_similarity(graph1, graph2):\n",
    "    \"\"\"Calculate structural similarity based on graph properties\"\"\"\n",
    "    stats1 = {\n",
    "        'nodes': graph1.number_of_nodes(),\n",
    "        'edges': graph1.number_of_edges(),\n",
    "        'density': nx.density(graph1),\n",
    "        'avg_clustering': nx.average_clustering(graph1.to_undirected()) if graph1.number_of_nodes() > 0 else 0\n",
    "    }\n",
    "    \n",
    "    stats2 = {\n",
    "        'nodes': graph2.number_of_nodes(),\n",
    "        'edges': graph2.number_of_edges(),\n",
    "        'density': nx.density(graph2),\n",
    "        'avg_clustering': nx.average_clustering(graph2.to_undirected()) if graph2.number_of_nodes() > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Calculate normalized differences\n",
    "    similarities = []\n",
    "    for key in stats1.keys():\n",
    "        if stats1[key] + stats2[key] > 0:\n",
    "            sim = 1 - abs(stats1[key] - stats2[key]) / (stats1[key] + stats2[key])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "def calculate_semantic_similarity(graph1, graph2):\n",
    "    \"\"\"Calculate semantic similarity based on relation types\"\"\"\n",
    "    # Get relation distributions\n",
    "    relations1 = [data['relation'] for _, _, data in graph1.edges(data=True) if 'relation' in data]\n",
    "    relations2 = [data['relation'] for _, _, data in graph2.edges(data=True) if 'relation' in data]\n",
    "    \n",
    "    if not relations1 or not relations2:\n",
    "        return 0\n",
    "    \n",
    "    # Create relation frequency vectors\n",
    "    all_relations = list(set(relations1 + relations2))\n",
    "    \n",
    "    freq1 = np.array([relations1.count(rel) for rel in all_relations])\n",
    "    freq2 = np.array([relations2.count(rel) for rel in all_relations])\n",
    "    \n",
    "    # Normalize\n",
    "    freq1 = freq1 / np.sum(freq1) if np.sum(freq1) > 0 else freq1\n",
    "    freq2 = freq2 / np.sum(freq2) if np.sum(freq2) > 0 else freq2\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    dot_product = np.dot(freq1, freq2)\n",
    "    norms = np.linalg.norm(freq1) * np.linalg.norm(freq2)\n",
    "    \n",
    "    return dot_product / norms if norms > 0 else 0\n",
    "\n",
    "def calculate_path_similarity(graph1, graph2, sample_size=100):\n",
    "    \"\"\"Calculate similarity based on shortest paths between common nodes\"\"\"\n",
    "    common_nodes = list(set(graph1.nodes()).intersection(set(graph2.nodes())))\n",
    "    \n",
    "    if len(common_nodes) < 2:\n",
    "        return 0\n",
    "    \n",
    "    # Sample node pairs\n",
    "    sample_pairs = [(common_nodes[i], common_nodes[j]) \n",
    "                   for i in range(min(sample_size, len(common_nodes))) \n",
    "                   for j in range(i+1, min(sample_size, len(common_nodes)))]\n",
    "    \n",
    "    path_similarities = []\n",
    "    \n",
    "    for source, target in sample_pairs[:sample_size]:\n",
    "        try:\n",
    "            path1 = nx.shortest_path_length(graph1, source, target)\n",
    "            path2 = nx.shortest_path_length(graph2, source, target)\n",
    "            \n",
    "            # Similarity based on path length difference\n",
    "            max_path = max(path1, path2)\n",
    "            similarity = 1 - abs(path1 - path2) / max_path if max_path > 0 else 1\n",
    "            path_similarities.append(similarity)\n",
    "            \n",
    "        except nx.NetworkXNoPath:\n",
    "            # One or both graphs don't have a path\n",
    "            path_similarities.append(0)\n",
    "    \n",
    "    return np.mean(path_similarities) if path_similarities else 0\n",
    "\n",
    "print(\"Graph similarity functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2cbf65",
   "metadata": {},
   "source": [
    "# SECTION 9: CALCULATE SIMILARITY MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba33e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CALCULATING AGENT SIMILARITY MATRIX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "num_agents = len(agents)\n",
    "similarity_results = {\n",
    "    'jaccard': np.zeros((num_agents, num_agents)),\n",
    "    'weighted_jaccard': np.zeros((num_agents, num_agents)),\n",
    "    'node_overlap': np.zeros((num_agents, num_agents)),\n",
    "    'structural': np.zeros((num_agents, num_agents)),\n",
    "    'semantic': np.zeros((num_agents, num_agents)),\n",
    "    'path_based': np.zeros((num_agents, num_agents))\n",
    "}\n",
    "\n",
    "print(f\"Comparing {num_agents} agents pairwise...\")\n",
    "\n",
    "for i in range(num_agents):\n",
    "    for j in range(num_agents):\n",
    "        if i == j:\n",
    "            # Self-similarity is 1.0\n",
    "            for metric in similarity_results.keys():\n",
    "                similarity_results[metric][i][j] = 1.0\n",
    "        else:\n",
    "            graph1 = agents[i].graph\n",
    "            graph2 = agents[j].graph\n",
    "            \n",
    "            # Calculate all similarity metrics\n",
    "            similarity_results['jaccard'][i][j] = calculate_jaccard_similarity(graph1, graph2)\n",
    "            similarity_results['weighted_jaccard'][i][j] = calculate_weighted_jaccard_similarity(graph1, graph2)\n",
    "            similarity_results['node_overlap'][i][j] = calculate_node_overlap(graph1, graph2)\n",
    "            similarity_results['structural'][i][j] = calculate_structural_similarity(graph1, graph2)\n",
    "            similarity_results['semantic'][i][j] = calculate_semantic_similarity(graph1, graph2)\n",
    "            similarity_results['path_based'][i][j] = calculate_path_similarity(graph1, graph2)\n",
    "\n",
    "print(\"Similarity calculations completed!\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = {}\n",
    "for metric, matrix in similarity_results.items():\n",
    "    # Get upper triangle (excluding diagonal)\n",
    "    upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "    \n",
    "    summary_stats[metric] = {\n",
    "        'mean': np.mean(upper_triangle),\n",
    "        'std': np.std(upper_triangle),\n",
    "        'min': np.min(upper_triangle),\n",
    "        'max': np.max(upper_triangle),\n",
    "        'median': np.median(upper_triangle)\n",
    "    }\n",
    "\n",
    "print(\"\\nSimilarity Summary Statistics:\")\n",
    "for metric, stats in summary_stats.items():\n",
    "    print(f\"\\n{metric.upper()} Similarity:\")\n",
    "    print(f\"  Mean: {stats['mean']:.4f}\")\n",
    "    print(f\"  Std:  {stats['std']:.4f}\")\n",
    "    print(f\"  Range: [{stats['min']:.4f}, {stats['max']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40572b2d",
   "metadata": {},
   "source": [
    "# SECTION 10: AGENT PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36210d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AGENT PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect final agent statistics\n",
    "agent_performance = []\n",
    "\n",
    "for agent in agents:\n",
    "    stats = agent.get_graph_stats()\n",
    "    metrics = agent.training_metrics\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    total_decisions = sum(agent.decision_log.values())\n",
    "    accept_rate = agent.decision_log['ACCEPT'] / total_decisions if total_decisions > 0 else 0\n",
    "    reject_rate = agent.decision_log['REJECT'] / total_decisions if total_decisions > 0 else 0\n",
    "    review_rate = agent.decision_log['REVIEW'] / total_decisions if total_decisions > 0 else 0\n",
    "    \n",
    "    # False positive rate (accepting false triples)\n",
    "    false_acceptances = sum(1 for v in agent.validation_history \n",
    "                           if v['is_false'] and v['decision'] == 'ACCEPT')\n",
    "    false_positives = len([v for v in agent.validation_history if v['is_false']])\n",
    "    false_positive_rate = false_acceptances / false_positives if false_positives > 0 else 0\n",
    "    \n",
    "    # Get resolution statistics\n",
    "    resolution_stats = agent.get_resolution_stats()\n",
    "    \n",
    "    performance = {\n",
    "        'agent_id': agent.agent_id,\n",
    "        'final_accuracy': metrics['accuracy'],\n",
    "        'graph_nodes': stats['nodes'],\n",
    "        'graph_edges': stats['edges'],\n",
    "        'graph_density': stats['density'],\n",
    "        'avg_clustering': stats['avg_clustering'],\n",
    "        'connected_components': stats['connected_components'],\n",
    "        'triples_processed': metrics['triples_processed'],\n",
    "        'false_triples_detected': metrics['false_triples_detected'],\n",
    "        'accept_rate': accept_rate,\n",
    "        'reject_rate': reject_rate,\n",
    "        'review_rate': review_rate,\n",
    "        'false_positive_rate': false_positive_rate,\n",
    "        'avg_degree': stats['avg_degree'],\n",
    "        'resolution_rate': resolution_stats['resolution_rate'],\n",
    "        'forced_decisions': resolution_stats['forced_decisions'],\n",
    "        'pending_relations': resolution_stats['relations_pending']\n",
    "    }\n",
    "    \n",
    "    agent_performance.append(performance)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "perf_df = pd.DataFrame(agent_performance)\n",
    "\n",
    "print(\"\\nAgent Performance Summary:\")\n",
    "print(perf_df[['agent_id', 'final_accuracy', 'graph_nodes', 'graph_edges', \n",
    "               'accept_rate', 'reject_rate', 'false_positive_rate', \n",
    "               'resolution_rate', 'forced_decisions']].to_string(index=False))\n",
    "\n",
    "# Calculate performance statistics\n",
    "print(\"\\n\\nPerformance Statistics Across All Agents:\")\n",
    "print(f\"Average Accuracy: {perf_df['final_accuracy'].mean():.4f} ± {perf_df['final_accuracy'].std():.4f}\")\n",
    "print(f\"Average Graph Size: {perf_df['graph_nodes'].mean():.1f} nodes, {perf_df['graph_edges'].mean():.1f} edges\")\n",
    "print(f\"Average Accept Rate: {perf_df['accept_rate'].mean():.4f} ± {perf_df['accept_rate'].std():.4f}\")\n",
    "print(f\"Average False Positive Rate: {perf_df['false_positive_rate'].mean():.4f} ± {perf_df['false_positive_rate'].std():.4f}\")\n",
    "print(f\"Average Resolution Rate: {perf_df['resolution_rate'].mean():.4f} ± {perf_df['resolution_rate'].std():.4f}\")\n",
    "print(f\"Total Forced Decisions: {perf_df['forced_decisions'].sum()}\")\n",
    "print(f\"Remaining Pending Relations: {perf_df['pending_relations'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365da5d",
   "metadata": {},
   "source": [
    "# SECTION 11: STATISTICAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL ANALYSIS & HYPOTHESIS TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Test for Universal Semantic Structure\n",
    "print(\"\\n1. TESTING FOR UNIVERSAL SEMANTIC STRUCTURE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate overall similarity scores\n",
    "overall_similarities = []\n",
    "for metric, matrix in similarity_results.items():\n",
    "    upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "    mean_sim = np.mean(upper_triangle)\n",
    "    overall_similarities.append(mean_sim)\n",
    "    print(f\"{metric.upper()} - Mean similarity: {mean_sim:.4f}\")\n",
    "\n",
    "# Overall consistency score\n",
    "consistency_score = np.mean(overall_similarities)\n",
    "print(f\"\\nOVERALL CONSISTENCY SCORE: {consistency_score:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if consistency_score > 0.7:\n",
    "    interpretation = \"STRONG evidence for universal semantic structure\"\n",
    "elif consistency_score > 0.5:\n",
    "    interpretation = \"MODERATE evidence for universal semantic structure\"\n",
    "else:\n",
    "    interpretation = \"WEAK evidence for universal semantic structure\"\n",
    "\n",
    "print(f\"INTERPRETATION: {interpretation}\")\n",
    "\n",
    "# 2. Statistical Tests\n",
    "print(\"\\n\\n2. STATISTICAL SIGNIFICANCE TESTS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Test if similarities are significantly above random\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "random_baseline = 0.2  # Expected similarity for random graphs\n",
    "\n",
    "for metric, matrix in similarity_results.items():\n",
    "    upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "    t_stat, p_value = ttest_1samp(upper_triangle, random_baseline)\n",
    "    \n",
    "    print(f\"\\n{metric.upper()} vs Random Baseline:\")\n",
    "    print(f\"  T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.6f}\")\n",
    "    print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# 3. Robustness Analysis\n",
    "print(\"\\n\\n3. ROBUSTNESS TO FALSE TRIPLES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze correlation between false positive rate and graph similarity\n",
    "# Calculate average similarity for each agent\n",
    "agent_avg_similarities = []\n",
    "for i in range(num_agents):\n",
    "    similarities = []\n",
    "    for j in range(num_agents):\n",
    "        if i != j:\n",
    "            # Average across all metrics\n",
    "            avg_sim = np.mean([similarity_results[metric][i][j] \n",
    "                              for metric in similarity_results.keys()])\n",
    "            similarities.append(avg_sim)\n",
    "    agent_avg_similarities.append(np.mean(similarities))\n",
    "\n",
    "# Correlation with false positive rate\n",
    "corr_coef, p_value = pearsonr(perf_df['false_positive_rate'], agent_avg_similarities)\n",
    "print(f\"Correlation between False Positive Rate and Average Similarity:\")\n",
    "print(f\"  Pearson correlation: {corr_coef:.4f}\")\n",
    "print(f\"  P-value: {p_value:.6f}\")\n",
    "print(f\"  Interpretation: {'Robust' if abs(corr_coef) < 0.3 else 'Sensitive'} to false triples\")\n",
    "\n",
    "# 4. Convergence Analysis\n",
    "print(\"\\n\\n4. TRAINING CONVERGENCE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze if agents converged to similar solutions\n",
    "final_accuracies = perf_df['final_accuracy'].values\n",
    "accuracy_variance = np.var(final_accuracies)\n",
    "accuracy_cv = np.std(final_accuracies) / np.mean(final_accuracies)  # Coefficient of variation\n",
    "\n",
    "print(f\"Final Accuracy Statistics:\")\n",
    "print(f\"  Mean: {np.mean(final_accuracies):.4f}\")\n",
    "print(f\"  Variance: {accuracy_variance:.6f}\")\n",
    "print(f\"  Coefficient of Variation: {accuracy_cv:.4f}\")\n",
    "print(f\"  Convergence: {'High' if accuracy_cv < 0.1 else 'Moderate' if accuracy_cv < 0.2 else 'Low'}\")\n",
    "\n",
    "# 5. Graph Structure Consistency\n",
    "print(\"\\n\\n5. GRAPH STRUCTURE CONSISTENCY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze consistency in graph properties\n",
    "structural_properties = ['graph_density', 'avg_clustering', 'avg_degree']\n",
    "structural_consistency = {}\n",
    "\n",
    "for prop in structural_properties:\n",
    "    values = perf_df[prop].values\n",
    "    cv = np.std(values) / np.mean(values) if np.mean(values) > 0 else 0\n",
    "    structural_consistency[prop] = cv\n",
    "    print(f\"{prop.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Mean: {np.mean(values):.4f}\")\n",
    "    print(f\"  CV: {cv:.4f}\")\n",
    "    print(f\"  Consistency: {'High' if cv < 0.2 else 'Moderate' if cv < 0.5 else 'Low'}\")\n",
    "    print()\n",
    "\n",
    "# Overall structural consistency\n",
    "overall_structural_consistency = np.mean(list(structural_consistency.values()))\n",
    "print(f\"Overall Structural Consistency (lower is better): {overall_structural_consistency:.4f}\")\n",
    "\n",
    "print(\"\\nStatistical analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4bbbe",
   "metadata": {},
   "source": [
    "# SECTION 12: ENHANCED THEORY VALIDATION METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4963baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENHANCED THEORY VALIDATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def structural_isomorphism_index(agents):\n",
    "    \"\"\"Calculate degree sequence similarity - core evidence for structural isomorphism\"\"\"\n",
    "    iso_scores = []\n",
    "    \n",
    "    for i in range(len(agents)):\n",
    "        for j in range(i+1, len(agents)):\n",
    "            # Get degree sequences\n",
    "            deg_seq1 = sorted([d for n, d in agents[i].graph.degree()], reverse=True)\n",
    "            deg_seq2 = sorted([d for n, d in agents[j].graph.degree()], reverse=True)\n",
    "            \n",
    "            if not deg_seq1 or not deg_seq2:\n",
    "                continue\n",
    "                \n",
    "            # Pad sequences to same length\n",
    "            max_len = max(len(deg_seq1), len(deg_seq2))\n",
    "            deg_seq1.extend([0] * (max_len - len(deg_seq1)))\n",
    "            deg_seq2.extend([0] * (max_len - len(deg_seq2)))\n",
    "            \n",
    "            # Calculate Pearson correlation\n",
    "            if len(deg_seq1) > 1:\n",
    "                correlation, _ = pearsonr(deg_seq1, deg_seq2)\n",
    "                if not np.isnan(correlation):\n",
    "                    iso_scores.append(correlation)\n",
    "    \n",
    "    return np.mean(iso_scores) if iso_scores else 0\n",
    "\n",
    "def semantic_coherence_score(agents):\n",
    "    \"\"\"Measure if agents discover same semantic relationships\"\"\"\n",
    "    print(\"  Calculating semantic relationship coherence...\")\n",
    "    \n",
    "    # Get all relation types across agents\n",
    "    all_relations = set()\n",
    "    for agent in agents:\n",
    "        for _, _, data in agent.graph.edges(data=True):\n",
    "            if 'relation' in data:\n",
    "                all_relations.add(data['relation'])\n",
    "    \n",
    "    coherence_scores = []\n",
    "    \n",
    "    for relation_type in all_relations:\n",
    "        relation_graphs = []\n",
    "        \n",
    "        for agent in agents:\n",
    "            # Extract edges for this relation type\n",
    "            edges = set()\n",
    "            for u, v, d in agent.graph.edges(data=True):\n",
    "                if d.get('relation') == relation_type:\n",
    "                    edges.add((u, v))\n",
    "            relation_graphs.append(edges)\n",
    "        \n",
    "        # Calculate pairwise Jaccard similarity for this relation\n",
    "        similarities = []\n",
    "        for i in range(len(relation_graphs)):\n",
    "            for j in range(i+1, len(relation_graphs)):\n",
    "                if relation_graphs[i] or relation_graphs[j]:\n",
    "                    intersection = len(relation_graphs[i] & relation_graphs[j])\n",
    "                    union = len(relation_graphs[i] | relation_graphs[j])\n",
    "                    jaccard = intersection / union if union > 0 else 0\n",
    "                    similarities.append(jaccard)\n",
    "        \n",
    "        if similarities:\n",
    "            coherence_scores.append(np.mean(similarities))\n",
    "    \n",
    "    return np.mean(coherence_scores) if coherence_scores else 0\n",
    "\n",
    "def rejection_consistency(agents):\n",
    "    \"\"\"How consistently do agents reject the same false triples?\"\"\"\n",
    "    print(\"  Analyzing false triple rejection consistency...\")\n",
    "    \n",
    "    false_triple_decisions = {}\n",
    "    \n",
    "    for agent in agents:\n",
    "        for entry in agent.validation_history:\n",
    "            if entry['is_false']:\n",
    "                triple_key = str(entry['triple'])\n",
    "                if triple_key not in false_triple_decisions:\n",
    "                    false_triple_decisions[triple_key] = []\n",
    "                false_triple_decisions[triple_key].append(entry['decision'])\n",
    "    \n",
    "    # Calculate consistency for each false triple\n",
    "    consistencies = []\n",
    "    for decisions in false_triple_decisions.values():\n",
    "        if len(decisions) > 1:\n",
    "            # Fraction of agents that made the most common decision\n",
    "            decision_counts = Counter(decisions)\n",
    "            most_common_count = decision_counts.most_common(1)[0][1]\n",
    "            consistency = most_common_count / len(decisions)\n",
    "            consistencies.append(consistency)\n",
    "    \n",
    "    return np.mean(consistencies) if consistencies else 0\n",
    "\n",
    "def path_structure_convergence(agents, sample_nodes=50):\n",
    "    \"\"\"Do agents develop similar path structures?\"\"\"\n",
    "    print(\"  Measuring path structure convergence...\")\n",
    "    \n",
    "    # Get common nodes across all agents\n",
    "    common_nodes = set(agents[0].graph.nodes())\n",
    "    for agent in agents[1:]:\n",
    "        common_nodes &= set(agent.graph.nodes())\n",
    "    \n",
    "    if len(common_nodes) < 10:\n",
    "        return 0\n",
    "    \n",
    "    sample_nodes_list = list(common_nodes)[:min(sample_nodes, len(common_nodes))]\n",
    "    path_similarities = []\n",
    "    \n",
    "    for i in range(len(agents)):\n",
    "        for j in range(i+1, len(agents)):\n",
    "            node_path_sims = []\n",
    "            \n",
    "            # Sample pairs of nodes for path analysis\n",
    "            sample_pairs = [(sample_nodes_list[k], sample_nodes_list[l]) \n",
    "                           for k in range(min(10, len(sample_nodes_list))) \n",
    "                           for l in range(k+1, min(20, len(sample_nodes_list)))]\n",
    "            \n",
    "            for source, target in sample_pairs[:100]:  # Limit for performance\n",
    "                try:\n",
    "                    path1 = nx.shortest_path_length(agents[i].graph, source, target)\n",
    "                    path2 = nx.shortest_path_length(agents[j].graph, source, target)\n",
    "                    \n",
    "                    # Path length similarity\n",
    "                    if path1 > 0 and path2 > 0:\n",
    "                        sim = 1 - abs(path1 - path2) / max(path1, path2)\n",
    "                        node_path_sims.append(sim)\n",
    "                except nx.NetworkXNoPath:\n",
    "                    # If one agent has path but other doesn't, similarity is 0\n",
    "                    node_path_sims.append(0)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if node_path_sims:\n",
    "                path_similarities.append(np.mean(node_path_sims))\n",
    "    \n",
    "    return np.mean(path_similarities) if path_similarities else 0\n",
    "\n",
    "def concept_clustering_similarity(agents):\n",
    "    \"\"\"Do agents cluster concepts similarly?\"\"\"\n",
    "    print(\"  Computing concept clustering similarity...\")\n",
    "    \n",
    "    # Get common nodes\n",
    "    common_nodes = set(agents[0].graph.nodes())\n",
    "    for agent in agents[1:]:\n",
    "        common_nodes &= set(agent.graph.nodes())\n",
    "    \n",
    "    if len(common_nodes) < 20:\n",
    "        return 0\n",
    "    \n",
    "    common_nodes = list(common_nodes)[:100]  # Limit for performance\n",
    "    \n",
    "    # Create feature vectors for each agent\n",
    "    agent_features = []\n",
    "    for agent in agents:\n",
    "        features = []\n",
    "        for node in common_nodes:\n",
    "            # Feature: neighbors count, degree, clustering coefficient\n",
    "            neighbors = len(list(agent.graph.neighbors(node)))\n",
    "            degree = agent.graph.degree(node)\n",
    "            \n",
    "            # Local clustering coefficient\n",
    "            try:\n",
    "                clustering = nx.clustering(agent.graph.to_undirected(), node)\n",
    "            except:\n",
    "                clustering = 0\n",
    "                \n",
    "            features.append([neighbors, degree, clustering])\n",
    "        agent_features.append(features)\n",
    "    \n",
    "    # Compare clustering results\n",
    "    clustering_scores = []\n",
    "    n_clusters = min(5, len(common_nodes) // 4)  # Adaptive cluster count\n",
    "    \n",
    "    if n_clusters < 2:\n",
    "        return 0\n",
    "    \n",
    "    for i in range(len(agents)):\n",
    "        for j in range(i+1, len(agents)):\n",
    "            try:\n",
    "                # Ensure we have enough samples for clustering\n",
    "                if len(agent_features[i]) < n_clusters or len(agent_features[j]) < n_clusters:\n",
    "                    continue\n",
    "                    \n",
    "                kmeans1 = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "                kmeans2 = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "                \n",
    "                labels1 = kmeans1.fit_predict(agent_features[i])\n",
    "                labels2 = kmeans2.fit_predict(agent_features[j])\n",
    "                \n",
    "                ari = adjusted_rand_score(labels1, labels2)\n",
    "                clustering_scores.append(ari)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    return np.mean(clustering_scores) if clustering_scores else 0\n",
    "\n",
    "print(\"Enhanced metric functions defined successfully!\")\n",
    "\n",
    "# Calculate Enhanced Metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CALCULATING ENHANCED VALIDATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate all enhanced metrics\n",
    "enhanced_metrics = {}\n",
    "\n",
    "print(\"\\n1. Structural Isomorphism Index...\")\n",
    "enhanced_metrics['structural_isomorphism'] = structural_isomorphism_index(agents)\n",
    "\n",
    "print(\"\\n2. Semantic Relationship Coherence...\")\n",
    "enhanced_metrics['semantic_coherence'] = semantic_coherence_score(agents)\n",
    "\n",
    "print(\"\\n3. False Triple Rejection Consistency...\")\n",
    "enhanced_metrics['rejection_consistency'] = rejection_consistency(agents)\n",
    "\n",
    "print(\"\\n4. Path Structure Convergence...\")\n",
    "enhanced_metrics['path_convergence'] = path_structure_convergence(agents)\n",
    "\n",
    "print(\"\\n5. Concept Clustering Similarity...\")\n",
    "enhanced_metrics['clustering_similarity'] = concept_clustering_similarity(agents)\n",
    "\n",
    "# Calculate enhanced theory validation score\n",
    "enhanced_metrics['weighted_validation'] = (\n",
    "    0.4 * enhanced_metrics['structural_isomorphism'] +\n",
    "    0.25 * enhanced_metrics['semantic_coherence'] +\n",
    "    0.15 * enhanced_metrics['rejection_consistency'] +\n",
    "    0.15 * enhanced_metrics['path_convergence'] +\n",
    "    0.05 * enhanced_metrics['clustering_similarity']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENHANCED METRICS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric, value in enhanced_metrics.items():\n",
    "    print(f\"{metric.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "# Define evidence thresholds\n",
    "evidence_thresholds = {\n",
    "    'structural_isomorphism': 0.7,      # High structural similarity\n",
    "    'semantic_coherence': 0.6,          # Consistent semantic relationships  \n",
    "    'rejection_consistency': 0.8,       # Strong false-triple agreement\n",
    "    'path_convergence': 0.5,            # Moderate path similarity\n",
    "    'clustering_similarity': 0.4,       # Moderate clustering agreement\n",
    "    'weighted_validation': 0.65         # Overall validation threshold\n",
    "}\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"THEORY VALIDATION ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "evidence_count = 0\n",
    "total_metrics = len(evidence_thresholds)\n",
    "\n",
    "for metric, threshold in evidence_thresholds.items():\n",
    "    value = enhanced_metrics[metric]\n",
    "    meets_threshold = value >= threshold\n",
    "    evidence_count += meets_threshold\n",
    "    \n",
    "    status = \"✓ PASS\" if meets_threshold else \"✗ FAIL\"\n",
    "    print(f\"{metric.replace('_', ' ').title()}: {value:.4f} (threshold: {threshold:.2f}) {status}\")\n",
    "\n",
    "# Overall assessment\n",
    "evidence_strength = evidence_count / total_metrics\n",
    "\n",
    "print(f\"\\nEvidence Strength: {evidence_count}/{total_metrics} metrics pass ({evidence_strength:.1%})\")\n",
    "\n",
    "if evidence_strength >= 0.8:\n",
    "    final_assessment = \"STRONG evidence for universal semantic structure theory\"\n",
    "elif evidence_strength >= 0.6:\n",
    "    final_assessment = \"MODERATE evidence for universal semantic structure theory\"  \n",
    "else:\n",
    "    final_assessment = \"WEAK evidence - requires further investigation\"\n",
    "\n",
    "print(f\"\\nFINAL ASSESSMENT: {final_assessment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4c504",
   "metadata": {},
   "source": [
    "# SECTION 13: VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# List of plotting functions for each plot\n",
    "plot_functions = []\n",
    "\n",
    "# 1-6. Similarity Heatmaps (improved, one per figure, larger size)\n",
    "for idx, (metric, matrix) in enumerate(similarity_results.items(), 1):\n",
    "    def plot_heatmap(metric=metric, matrix=matrix):\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))  # Larger size\n",
    "        mask = np.eye(len(matrix), dtype=bool)\n",
    "        sns.heatmap(matrix, annot=True, fmt='.3f', cmap='coolwarm',\n",
    "                    xticklabels=[f'A{i+1}' for i in range(num_agents)],\n",
    "                    yticklabels=[f'A{i+1}' for i in range(num_agents)],\n",
    "                    cbar=True, mask=mask, ax=ax, annot_kws={\"size\": 14})\n",
    "        ax.set_title(f'{metric.replace(\"_\", \" \").title()} Similarity', fontsize=20)\n",
    "        upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "        ax.text(0.5, 1.05, f\"Mean: {np.mean(upper_triangle):.2f}\", transform=ax.transAxes, ha='center', fontsize=16)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    plot_functions.append(plot_heatmap)\n",
    "\n",
    "# 7. Training Progress (smoothed)\n",
    "def plot_training_progress():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    training_df = pd.DataFrame(training_history)\n",
    "    for agent_id in training_df['agent_id'].unique():\n",
    "        agent_data = training_df[training_df['agent_id'] == agent_id]\n",
    "        if len(agent_data) > 5:\n",
    "            smoothed = agent_data['accuracy'].rolling(window=5, min_periods=1).mean()\n",
    "        else:\n",
    "            smoothed = agent_data['accuracy']\n",
    "        ax.plot(agent_data['iteration'], smoothed, label=agent_id, alpha=0.7, linewidth=3)\n",
    "    ax.set_xlabel('Training Iteration', fontsize=16)\n",
    "    ax.set_ylabel('Validation Accuracy', fontsize=16)\n",
    "    ax.set_title('Training Progress by Agent (Smoothed)', fontsize=20)\n",
    "    ax.legend(fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_training_progress)\n",
    "\n",
    "# 8. Graph Size Distribution (trend line)\n",
    "def plot_graph_size():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    scatter = ax.scatter(perf_df['graph_nodes'], perf_df['graph_edges'], \n",
    "                        c=perf_df['final_accuracy'], cmap='viridis', s=200, alpha=0.8)\n",
    "    plt.colorbar(scatter, ax=ax, label='Final Accuracy')\n",
    "    ax.set_xlabel('Number of Nodes', fontsize=16)\n",
    "    ax.set_ylabel('Number of Edges', fontsize=16)\n",
    "    ax.set_title('Graph Size vs Accuracy', fontsize=20)\n",
    "    z = np.polyfit(perf_df['graph_nodes'], perf_df['graph_edges'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(perf_df['graph_nodes'], p(perf_df['graph_nodes']), \"r--\", alpha=0.5)\n",
    "    for i, agent_id in enumerate(perf_df['agent_id']):\n",
    "        ax.annotate(agent_id.split('_')[1], \n",
    "                    (perf_df.iloc[i]['graph_nodes'], perf_df.iloc[i]['graph_edges']),\n",
    "                    xytext=(8, 8), textcoords='offset points', fontsize=14)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_graph_size)\n",
    "\n",
    "# 9. Decision Distribution (percent labels)\n",
    "def plot_decision_distribution():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    decision_data = perf_df[['accept_rate', 'reject_rate', 'review_rate']]\n",
    "    decision_data.plot(kind='bar', stacked=True, ax=ax, color=['#4CAF50', '#F44336', '#FFC107'])\n",
    "    ax.set_xlabel('Agent', fontsize=16)\n",
    "    ax.set_ylabel('Decision Rate', fontsize=16)\n",
    "    ax.set_title('Decision Distribution by Agent', fontsize=20)\n",
    "    ax.set_xticks(range(len(perf_df)))\n",
    "    ax.set_xticklabels([f'A{i+1}' for i in range(len(perf_df))], rotation=0, fontsize=14)\n",
    "    ax.legend(['Accept', 'Reject', 'Review'], fontsize=14)\n",
    "    for idx, row in decision_data.iterrows():\n",
    "        y = 0\n",
    "        for val in row:\n",
    "            ax.text(idx, y + val/2, f\"{val*100:.1f}%\", ha='center', va='center', fontsize=14, color='white')\n",
    "            y += val\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_decision_distribution)\n",
    "\n",
    "# 10. Similarity Distribution (mean/median lines)\n",
    "def plot_similarity_distribution():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    all_similarities = []\n",
    "    metric_labels = []\n",
    "    for metric, matrix in similarity_results.items():\n",
    "        upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "        all_similarities.extend(upper_triangle)\n",
    "        metric_labels.extend([metric] * len(upper_triangle))\n",
    "    sim_df = pd.DataFrame({'similarity': all_similarities, 'metric': metric_labels})\n",
    "    sns.boxplot(data=sim_df, x='metric', y='similarity', ax=ax)\n",
    "    ax.set_xlabel('Similarity Metric', fontsize=16)\n",
    "    ax.set_ylabel('Similarity Score', fontsize=16)\n",
    "    ax.set_title('Distribution of Similarity Scores', fontsize=20)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=14)\n",
    "    for i, metric in enumerate(sim_df['metric'].unique()):\n",
    "        vals = sim_df[sim_df['metric'] == metric]['similarity']\n",
    "        ax.plot([i-0.2, i+0.2], [vals.mean()]*2, 'g-', lw=3)\n",
    "        ax.plot([i-0.2, i+0.2], [vals.median()]*2, 'b--', lw=3)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_similarity_distribution)\n",
    "\n",
    "# 11. Performance Correlation (fit line, corr coef)\n",
    "def plot_performance_correlation():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    x = perf_df['false_positive_rate']\n",
    "    y = perf_df['final_accuracy']\n",
    "    ax.scatter(x, y, s=200, alpha=0.8, c='red')\n",
    "    if len(x) > 1:\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(x, p(x), \"b--\", alpha=0.7, linewidth=3)\n",
    "        corr = np.corrcoef(x, y)[0, 1]\n",
    "        ax.text(0.05, 0.95, f\"r={corr:.2f}\", transform=ax.transAxes, fontsize=16, ha='left', va='top')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=16)\n",
    "    ax.set_ylabel('Final Accuracy', fontsize=16)\n",
    "    ax.set_title('Accuracy vs False Positive Rate', fontsize=20)\n",
    "    for i, agent_id in enumerate(perf_df['agent_id']):\n",
    "        ax.annotate(agent_id.split('_')[1], \n",
    "                    (perf_df.iloc[i]['false_positive_rate'], perf_df.iloc[i]['final_accuracy']),\n",
    "                    xytext=(8, 8), textcoords='offset points', fontsize=14)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_performance_correlation)\n",
    "\n",
    "# 12. Graph Density Analysis (mean/std lines)\n",
    "def plot_graph_density():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.hist(perf_df['graph_density'], bins=10, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Graph Density', fontsize=16)\n",
    "    ax.set_ylabel('Frequency', fontsize=16)\n",
    "    ax.set_title('Distribution of Graph Densities', fontsize=20)\n",
    "    ax.axvline(perf_df['graph_density'].mean(), color='red', linestyle='--', label=f'Mean: {perf_df[\"graph_density\"].mean():.4f}')\n",
    "    ax.axvline(perf_df['graph_density'].mean() + perf_df['graph_density'].std(), color='blue', linestyle=':', label='±1 Std')\n",
    "    ax.axvline(perf_df['graph_density'].mean() - perf_df['graph_density'].std(), color='blue', linestyle=':')\n",
    "    ax.legend(fontsize=14)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_graph_density)\n",
    "\n",
    "# 13. Clustering Coefficient (mean line)\n",
    "def plot_clustering_coefficient():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.bar(range(len(perf_df)), perf_df['avg_clustering'], alpha=0.7, color='#2196F3')\n",
    "    ax.set_xlabel('Agent', fontsize=16)\n",
    "    ax.set_ylabel('Average Clustering Coefficient', fontsize=16)\n",
    "    ax.set_title('Clustering by Agent', fontsize=20)\n",
    "    ax.set_xticks(range(len(perf_df)))\n",
    "    ax.set_xticklabels([f'A{i+1}' for i in range(len(perf_df))], fontsize=14)\n",
    "    ax.axhline(perf_df['avg_clustering'].mean(), color='red', linestyle='--', label='Mean')\n",
    "    ax.legend(fontsize=14)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_clustering_coefficient)\n",
    "\n",
    "# 14. Resolution Performance Analysis\n",
    "def plot_resolution_performance():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Left plot: Resolution rates by agent\n",
    "    ax1.bar(range(len(perf_df)), perf_df['resolution_rate'], alpha=0.7, color='#4CAF50')\n",
    "    ax1.set_xlabel('Agent', fontsize=14)\n",
    "    ax1.set_ylabel('Resolution Rate', fontsize=14)\n",
    "    ax1.set_title('Resolution Rate by Agent', fontsize=16)\n",
    "    ax1.set_xticks(range(len(perf_df)))\n",
    "    ax1.set_xticklabels([f'A{i+1}' for i in range(len(perf_df))], fontsize=12)\n",
    "    ax1.axhline(perf_df['resolution_rate'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {perf_df[\"resolution_rate\"].mean():.3f}')\n",
    "    ax1.legend(fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(perf_df['resolution_rate']):\n",
    "        ax1.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Right plot: Forced decisions vs accuracy\n",
    "    scatter = ax2.scatter(perf_df['forced_decisions'], perf_df['final_accuracy'], \n",
    "                         s=200, alpha=0.8, c=perf_df['resolution_rate'], cmap='viridis')\n",
    "    plt.colorbar(scatter, ax=ax2, label='Resolution Rate')\n",
    "    ax2.set_xlabel('Forced Decisions', fontsize=14)\n",
    "    ax2.set_ylabel('Final Accuracy', fontsize=14)\n",
    "    ax2.set_title('Forced Decisions vs Accuracy', fontsize=16)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    if len(perf_df['forced_decisions']) > 1:\n",
    "        corr = np.corrcoef(perf_df['forced_decisions'], perf_df['final_accuracy'])[0, 1]\n",
    "        ax2.text(0.05, 0.95, f'r = {corr:.3f}', transform=ax2.transAxes, \n",
    "                fontsize=12, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Annotate points with agent names\n",
    "    for i, agent_id in enumerate(perf_df['agent_id']):\n",
    "        ax2.annotate(agent_id.split('_')[1], \n",
    "                    (perf_df.iloc[i]['forced_decisions'], perf_df.iloc[i]['final_accuracy']),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "    \n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_resolution_performance)\n",
    "\n",
    "# 15. Weighted vs Unweighted Jaccard (highlight outliers)\n",
    "def plot_jaccard_comparison():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    jaccard_upper = similarity_results['jaccard'][np.triu_indices_from(similarity_results['jaccard'], k=1)]\n",
    "    weighted_jaccard_upper = similarity_results['weighted_jaccard'][np.triu_indices_from(similarity_results['weighted_jaccard'], k=1)]\n",
    "    ax.scatter(jaccard_upper, weighted_jaccard_upper, alpha=0.8, s=200)\n",
    "    ax.plot([0, 1], [0, 1], 'r--', alpha=0.8, label='Perfect correlation', linewidth=3)\n",
    "    if len(jaccard_upper) > 0:\n",
    "        diffs = np.abs(jaccard_upper - weighted_jaccard_upper)\n",
    "        outlier_idx = np.argsort(diffs)[-2:]\n",
    "        ax.scatter(np.array(jaccard_upper)[outlier_idx], np.array(weighted_jaccard_upper)[outlier_idx], color='orange', s=300, edgecolor='black', label='Outliers')\n",
    "    ax.set_xlabel('Standard Jaccard Similarity', fontsize=16)\n",
    "    ax.set_ylabel('Weighted Jaccard Similarity', fontsize=16)\n",
    "    ax.set_title('Weighted vs Standard Jaccard', fontsize=20)\n",
    "    ax.legend(fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_functions.append(plot_jaccard_comparison)\n",
    "\n",
    "# Now, call each plotting function in sequence to display each plot in full size\n",
    "for plot_func in plot_functions:\n",
    "    plot_func()\n",
    "\n",
    "print(\"Visualizations generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0718e33",
   "metadata": {},
   "source": [
    "# SECTION 14: ENHANCED VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b84577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENHANCED THEORY VALIDATION VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Enhanced Metrics Radar Chart\n",
    "fig, ax1 = plt.subplots(figsize=(8, 7))\n",
    "metrics_names = list(enhanced_metrics.keys())\n",
    "metrics_values = list(enhanced_metrics.values())\n",
    "angles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False)\n",
    "values = metrics_values + [metrics_values[0]]\n",
    "angles = np.concatenate((angles, [angles[0]]))\n",
    "ax1.plot(angles, values, 'o-', linewidth=2, label='Achieved', color='navy')\n",
    "ax1.fill(angles, values, alpha=0.25, color='navy')\n",
    "thresholds = [evidence_thresholds.get(name, 0.5) for name in metrics_names] + [evidence_thresholds.get(metrics_names[0], 0.5)]\n",
    "ax1.plot(angles, thresholds, '--', linewidth=2, color='red', label='Threshold')\n",
    "ax1.fill_between(angles, values, thresholds, where=(np.array(values) < np.array(thresholds)), color='orange', alpha=0.2)\n",
    "ax1.set_xticks(angles[:-1])\n",
    "ax1.set_xticklabels([name.replace('_', '\\n').title() for name in metrics_names], fontsize=9)\n",
    "\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_title('Theory Validation Radar')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "max_idx = np.argmax(metrics_values)\n",
    "min_idx = np.argmin(metrics_values)\n",
    "ax1.annotate(f\"Max: {metrics_names[max_idx].replace('_',' ').title()}\\n{metrics_values[max_idx]:.2f}\",\n",
    "             (angles[max_idx], metrics_values[max_idx]), textcoords=\"offset points\", xytext=(10,10), ha='left', color='green')\n",
    "ax1.annotate(f\"Min: {metrics_names[min_idx].replace('_',' ').title()}\\n{metrics_values[min_idx]:.2f}\",\n",
    "             (angles[min_idx], metrics_values[min_idx]), textcoords=\"offset points\", xytext=(-60,-20), ha='left', color='red')\n",
    "plt.show()\n",
    "\n",
    "# 2. Structural Isomorphism Heatmap\n",
    "fig, ax2 = plt.subplots(figsize=(7, 6))\n",
    "iso_matrix = np.zeros((len(agents), len(agents)))\n",
    "for i in range(len(agents)):\n",
    "    for j in range(len(agents)):\n",
    "        if i == j:\n",
    "            iso_matrix[i][j] = 1.0\n",
    "        else:\n",
    "            deg_seq1 = sorted([d for n, d in agents[i].graph.degree()], reverse=True)\n",
    "            deg_seq2 = sorted([d for n, d in agents[j].graph.degree()], reverse=True)\n",
    "            if deg_seq1 and deg_seq2:\n",
    "                max_len = max(len(deg_seq1), len(deg_seq2))\n",
    "                deg_seq1.extend([0] * (max_len - len(deg_seq1)))\n",
    "                deg_seq2.extend([0] * (max_len - len(deg_seq2)))\n",
    "                if len(deg_seq1) > 1:\n",
    "                    corr, _ = pearsonr(deg_seq1, deg_seq2)\n",
    "                    iso_matrix[i][j] = corr if not np.isnan(corr) else 0\n",
    "sns.heatmap(iso_matrix, annot=True, fmt='.3f', cmap='vlag', ax=ax2,\n",
    "            xticklabels=[f'A{i+1}' for i in range(len(agents))],\n",
    "            yticklabels=[f'A{i+1}' for i in range(len(agents))], cbar=True)\n",
    "ax2.set_title(f'Structural Isomorphism Matrix\\nMean: {np.mean(iso_matrix[np.triu_indices_from(iso_matrix, k=1)]):.2f}')\n",
    "plt.show()\n",
    "\n",
    "# 3. Evidence Strength Bar Chart\n",
    "fig, ax3 = plt.subplots(figsize=(8, 6))\n",
    "metric_names = [name.replace('_', ' ').title() for name in enhanced_metrics.keys()]\n",
    "metric_values = list(enhanced_metrics.values())\n",
    "threshold_values = [evidence_thresholds.get(name, 0.5) for name in enhanced_metrics.keys()]\n",
    "x_pos = np.arange(len(metric_names))\n",
    "bars = ax3.bar(x_pos, metric_values, alpha=0.7, color='steelblue', label='Achieved')\n",
    "ax3.bar(x_pos, threshold_values, alpha=0.3, color='red', label='Threshold')\n",
    "ax3.set_xlabel('Metrics')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('Evidence Strength by Metric')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(metric_names, rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "# Color bars and annotate\n",
    "for i, (bar, value, threshold) in enumerate(zip(bars, metric_values, threshold_values)):\n",
    "    if value >= threshold:\n",
    "        bar.set_color('green')\n",
    "    else:\n",
    "        bar.set_color('orange')\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, value + 0.02, f\"{value:.2f}\", ha='center', va='bottom', fontsize=9)\n",
    "    ax3.axhline(threshold, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# 4. Semantic Coherence by Relation Type\n",
    "fig, ax4 = plt.subplots(figsize=(8, 6))\n",
    "relation_coherence = {}\n",
    "all_relations = set()\n",
    "for agent in agents:\n",
    "    for _, _, data in agent.graph.edges(data=True):\n",
    "        if 'relation' in data:\n",
    "            all_relations.add(data['relation'])\n",
    "for relation_type in list(all_relations):\n",
    "    relation_graphs = []\n",
    "    for agent in agents:\n",
    "        edges = set()\n",
    "        for u, v, d in agent.graph.edges(data=True):\n",
    "            if d.get('relation') == relation_type:\n",
    "                edges.add((u, v))\n",
    "        relation_graphs.append(edges)\n",
    "    similarities = []\n",
    "    for i in range(len(relation_graphs)):\n",
    "        for j in range(i+1, len(relation_graphs)):\n",
    "            if relation_graphs[i] or relation_graphs[j]:\n",
    "                intersection = len(relation_graphs[i] & relation_graphs[j])\n",
    "                union = len(relation_graphs[i] | relation_graphs[j])\n",
    "                jaccard = intersection / union if union > 0 else 0\n",
    "                similarities.append(jaccard)\n",
    "    if similarities:\n",
    "        relation_coherence[relation_type] = np.mean(similarities)\n",
    "if relation_coherence:\n",
    "    sorted_items = sorted(relation_coherence.items(), key=lambda x: x[1], reverse=True)\n",
    "    relations = [k for k, v in sorted_items][:10]\n",
    "    coherence_vals = [v for k, v in sorted_items][:10]\n",
    "    bars = ax4.barh(relations, coherence_vals, alpha=0.7)\n",
    "    ax4.set_xlabel('Coherence Score')\n",
    "    ax4.set_title('Semantic Coherence by Relation Type (Top 10)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    # Highlight top 3 and bottom 3\n",
    "    for i, bar in enumerate(bars):\n",
    "        if i < 3:\n",
    "            bar.set_color('green')\n",
    "        elif i >= len(bars)-3:\n",
    "            bar.set_color('red')\n",
    "plt.show()\n",
    "\n",
    "# 5. Theory Validation Timeline\n",
    "fig, ax5 = plt.subplots(figsize=(8, 6))\n",
    "validation_scores = []\n",
    "for i in range(1, len(training_history)//len(agents) + 1):\n",
    "    iteration_data = [r for r in training_history if r.get('iteration') == i]\n",
    "    if iteration_data:\n",
    "        avg_accuracy = np.mean([r['accuracy'] for r in iteration_data])\n",
    "        avg_nodes = np.mean([r['graph_nodes'] for r in iteration_data])\n",
    "        val_score = (avg_accuracy + min(avg_nodes/1000, 1)) / 2\n",
    "        validation_scores.append(val_score)\n",
    "if validation_scores:\n",
    "    iterations = range(1, len(validation_scores) + 1)\n",
    "    ax5.plot(iterations, validation_scores, linewidth=2, marker='o')\n",
    "    ax5.axhline(y=0.65, color='red', linestyle='--', label='Validation Threshold')\n",
    "    ax5.fill_between(iterations, 0.65, 1, color='red', alpha=0.08)\n",
    "    ax5.set_xlabel('Training Iteration')\n",
    "    ax5.set_ylabel('Validation Score')\n",
    "    ax5.set_title('Theory Validation Over Time')\n",
    "    # Annotate first crossing\n",
    "    above = np.where(np.array(validation_scores) >= 0.65)[0]\n",
    "    if len(above) > 0:\n",
    "        ax5.annotate(f\"Threshold crossed at iter {above[0]+1}\", (above[0]+1, validation_scores[above[0]]),\n",
    "                     xytext=(above[0]+10, validation_scores[above[0]]+0.05),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05), fontsize=9)\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Final Assessment Summary\n",
    "fig, ax6 = plt.subplots(figsize=(8, 6))\n",
    "ax6.axis('off')\n",
    "assessment_text = f\"\"\"\n",
    "THEORY VALIDATION SUMMARY\n",
    "\n",
    "Overall Consistency Score: {consistency_score:.3f}\n",
    "Enhanced Validation Score: {enhanced_metrics['weighted_validation']:.3f}\n",
    "\n",
    "Key Findings:\n",
    "• Structural Isomorphism: {enhanced_metrics['structural_isomorphism']:.3f}\n",
    "• Semantic Coherence: {enhanced_metrics['semantic_coherence']:.3f}  \n",
    "• Rejection Consistency: {enhanced_metrics['rejection_consistency']:.3f}\n",
    "\n",
    "Evidence Strength: {evidence_strength:.1%}\n",
    "Assessment: {final_assessment}\n",
    "\n",
    "Conclusion:\n",
    "{\"✓ Theory VALIDATED\" if evidence_strength >= 0.6 else \"⚠ Theory INCONCLUSIVE\" if evidence_strength >= 0.4 else \"✗ Theory NOT SUPPORTED\"}\n",
    "\"\"\"\n",
    "# Add pass/fail icons for each key metric\n",
    "icon = lambda v, t: '🟢' if v >= t else '🔴'\n",
    "summary_lines = [\n",
    "    f\"{icon(enhanced_metrics['structural_isomorphism'], evidence_thresholds['structural_isomorphism'])} Structural Isomorphism\",\n",
    "    f\"{icon(enhanced_metrics['semantic_coherence'], evidence_thresholds['semantic_coherence'])} Semantic Coherence\",\n",
    "    f\"{icon(enhanced_metrics['rejection_consistency'], evidence_thresholds['rejection_consistency'])} Rejection Consistency\"\n",
    "]\n",
    "ax6.text(0.1, 0.9, assessment_text + '\\n' + '\\n'.join(summary_lines), transform=ax6.transAxes, fontsize=11,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "plt.show()\n",
    "\n",
    "print(\"Enhanced visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13473a06",
   "metadata": {},
   "source": [
    "# SECTION 15: COMPREHENSIVE REPORT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT REPORT GENERATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Helper function to convert numpy types to native Python types for JSON serialization\n",
    "def convert_for_json(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization\"\"\"\n",
    "    if hasattr(obj, 'item'):  # numpy scalar\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, (np.integer, int)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, float)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_for_json(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return [convert_for_json(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Create comprehensive experiment report\n",
    "experiment_report = {\n",
    "    'experiment_metadata': {\n",
    "        'experiment_name': CONFIG['experiment_name'],\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'num_agents': CONFIG['num_agents'],\n",
    "        'total_iterations': CONFIG['max_iterations'],\n",
    "        'sample_size': CONFIG['sample_size'],\n",
    "        'false_triple_ratio': CONFIG['false_triple_ratio'],\n",
    "        'batch_size': CONFIG['batch_size']\n",
    "    },\n",
    "    \n",
    "    'hypothesis_validation': {\n",
    "        'overall_consistency_score': convert_for_json(consistency_score),\n",
    "        'interpretation': interpretation,\n",
    "        'evidence_strength': 'Strong' if consistency_score > 0.7 else 'Moderate' if consistency_score > 0.5 else 'Weak'\n",
    "    },\n",
    "    \n",
    "    'similarity_analysis': {\n",
    "        'metrics': {metric: {\n",
    "            'mean': convert_for_json(summary_stats[metric]['mean']),\n",
    "            'std': convert_for_json(summary_stats[metric]['std']),\n",
    "            'min': convert_for_json(summary_stats[metric]['min']),\n",
    "            'max': convert_for_json(summary_stats[metric]['max'])\n",
    "        } for metric in summary_stats.keys()},\n",
    "        'overall_similarity': convert_for_json(consistency_score)\n",
    "    },\n",
    "    \n",
    "    'agent_performance': {\n",
    "        'individual_agents': convert_for_json(agent_performance),\n",
    "        'summary_statistics': {\n",
    "            'mean_accuracy': convert_for_json(perf_df['final_accuracy'].mean()),\n",
    "            'accuracy_std': convert_for_json(perf_df['final_accuracy'].std()),\n",
    "            'mean_graph_size': {\n",
    "                'nodes': convert_for_json(perf_df['graph_nodes'].mean()),\n",
    "                'edges': convert_for_json(perf_df['graph_edges'].mean())\n",
    "            },\n",
    "            'mean_false_positive_rate': convert_for_json(perf_df['false_positive_rate'].mean())\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'robustness_analysis': {\n",
    "        'false_triple_sensitivity': {\n",
    "            'correlation_coefficient': convert_for_json(corr_coef),\n",
    "            'p_value': convert_for_json(p_value),\n",
    "            'robustness_assessment': 'Robust' if abs(corr_coef) < 0.3 else 'Sensitive'\n",
    "        },\n",
    "        'convergence_metrics': {\n",
    "            'accuracy_variance': convert_for_json(accuracy_variance),\n",
    "            'coefficient_of_variation': convert_for_json(accuracy_cv),\n",
    "            'convergence_level': 'High' if accuracy_cv < 0.1 else 'Moderate' if accuracy_cv < 0.2 else 'Low'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'structural_consistency': {\n",
    "        'property_consistency': convert_for_json(structural_consistency),\n",
    "        'overall_consistency': convert_for_json(overall_structural_consistency)\n",
    "    },\n",
    "    \n",
    "    'enhanced_validation': {\n",
    "        'structural_isomorphism_index': convert_for_json(enhanced_metrics['structural_isomorphism']),\n",
    "        'semantic_coherence_score': convert_for_json(enhanced_metrics['semantic_coherence']),\n",
    "        'rejection_consistency': convert_for_json(enhanced_metrics['rejection_consistency']),\n",
    "        'path_structure_convergence': convert_for_json(enhanced_metrics['path_convergence']),\n",
    "        'concept_clustering_similarity': convert_for_json(enhanced_metrics['clustering_similarity']),\n",
    "        'weighted_validation_score': convert_for_json(enhanced_metrics['weighted_validation'])\n",
    "    },\n",
    "    \n",
    "    'theory_assessment': {\n",
    "        'evidence_strength': convert_for_json(evidence_strength),\n",
    "        'metrics_passing_threshold': convert_for_json(evidence_count),\n",
    "        'total_metrics_evaluated': convert_for_json(total_metrics),\n",
    "        'final_assessment': final_assessment,\n",
    "        'theory_validated': convert_for_json(evidence_strength >= 0.6),\n",
    "        'isomorphism_evidence': convert_for_json(enhanced_metrics['structural_isomorphism'] >= 0.7),\n",
    "        'semantic_consistency_evidence': convert_for_json(enhanced_metrics['semantic_coherence'] >= 0.6)\n",
    "    },\n",
    "    \n",
    "    'conclusions': {\n",
    "        'universal_structure_evidence': convert_for_json(consistency_score > 0.6),\n",
    "        'agent_convergence': convert_for_json(accuracy_cv < 0.15),\n",
    "        'robustness_to_noise': convert_for_json(abs(corr_coef) < 0.3),\n",
    "        'theory_validation_score': convert_for_json((consistency_score + (1 - accuracy_cv) + (1 - abs(corr_coef))) / 3),\n",
    "        'relational_meaning_validated': convert_for_json(enhanced_metrics['semantic_coherence'] > 0.5),\n",
    "        'structural_isomorphism_confirmed': convert_for_json(enhanced_metrics['structural_isomorphism'] > 0.6),\n",
    "        'self_correcting_behavior': convert_for_json(enhanced_metrics['rejection_consistency'] > 0.7),\n",
    "        'emergent_logical_patterns': convert_for_json(enhanced_metrics['path_convergence'] > 0.4),\n",
    "        'universal_semantic_principles': convert_for_json(enhanced_metrics['weighted_validation'] > 0.6),\n",
    "        'theoretical_validation_strength': convert_for_json(evidence_strength)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the entire report to ensure all nested values are JSON serializable\n",
    "experiment_report = convert_for_json(experiment_report)\n",
    "\n",
    "# Save experiment results\n",
    "output_file = OUTPUT_PATH / f\"multi_agent_experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(experiment_report, f, indent=2)\n",
    "\n",
    "print(f\"Experiment report saved to: {output_file}\")\n",
    "\n",
    "# Save detailed similarity results\n",
    "similarity_file = OUTPUT_PATH / f\"similarity_matrices_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "with open(similarity_file, 'wb') as f:\n",
    "    pickle.dump(similarity_results, f)\n",
    "\n",
    "print(f\"Similarity matrices saved to: {similarity_file}\")\n",
    "\n",
    "# Save agent graphs\n",
    "try:\n",
    "    import lxml\n",
    "except ImportError:\n",
    "    import sys\n",
    "    import subprocess\n",
    "    print(\"lxml not found. Installing lxml...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'lxml'])\n",
    "\n",
    "# Helper function to convert graph attributes\n",
    "import collections.abc\n",
    "def convert_graph_attributes_to_native(G):\n",
    "    for n, d in G.nodes(data=True):\n",
    "        for k, v in d.items():\n",
    "            if hasattr(v, 'item'):\n",
    "                d[k] = v.item()\n",
    "            elif isinstance(v, (np.generic, np.ndarray)):\n",
    "                d[k] = convert_for_json(v)\n",
    "            elif isinstance(v, collections.abc.Mapping):\n",
    "                d[k] = convert_for_json(v)\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        for k, val in d.items():\n",
    "            if hasattr(val, 'item'):\n",
    "                d[k] = val.item()\n",
    "            elif isinstance(val, (np.generic, np.ndarray)):\n",
    "                d[k] = convert_for_json(val)\n",
    "            elif isinstance(val, collections.abc.Mapping):\n",
    "                d[k] = convert_for_json(val)\n",
    "    return G\n",
    "\n",
    "for i, agent in enumerate(agents):\n",
    "    graph_file = OUTPUT_PATH / f\"agent_{i+1}_graph_{datetime.now().strftime('%Y%m%d_%H%M%S')}.graphml\"\n",
    "    G_native = convert_graph_attributes_to_native(agent.graph.copy())\n",
    "    nx.write_graphml(G_native, graph_file)\n",
    "    print(f\"Agent {i+1} graph saved to: {graph_file}\")\n",
    "\n",
    "print(\"\\nAll experiment data saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb984cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "### Key Findings\n",
    "\n",
    "1. **Universal Structure Evidence**: Based on the overall consistency score and cross-agent similarity metrics\n",
    "2. **Agent Convergence**: Analysis of whether agents independently arrived at similar semantic structures\n",
    "3. **Robustness to Noise**: How well agents maintained consistency despite false triple injection\n",
    "4. **Theory Validation**: Evidence for or against the hypothesis of universal meaning structures\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "- **Training Mode**: {final_training_mode}\n",
    "- **Overall Consistency Score**: {consistency_score:.4f}\n",
    "- **Enhanced Validation Score**: {enhanced_metrics['weighted_validation']:.4f}\n",
    "- **Evidence Strength**: {evidence_strength:.1%} ({evidence_count}/{total_metrics} metrics pass)\n",
    "- **Final Assessment**: {final_assessment}\n",
    "\n",
    "### Theoretical Implications\n",
    "\n",
    "If agents consistently build similar semantic structures despite:\n",
    "- Independent training\n",
    "- No shared optimization\n",
    "- Presence of false information\n",
    "- Different random initializations\n",
    "\n",
    "This provides strong evidence for an underlying universal theory of meaning that is:\n",
    "- Self-reinforcing\n",
    "- Contradiction-rejecting  \n",
    "- Logically consistent\n",
    "- Emergent from basic semantic relationships\n",
    "\n",
    "### Scalability Notes\n",
    "\n",
    "This experiment framework is designed to scale from small test datasets to the full 3M ConceptNet dataset:\n",
    "\n",
    "- **Sample Size**: Easily adjustable via CONFIG['sample_size']\n",
    "- **Agent Count**: Configurable number of agents for statistical power\n",
    "- **Iteration Control**: Adjustable training iterations for thoroughness\n",
    "- **Memory Management**: Efficient graph storage and processing\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Scale Up**: Run with larger datasets (100K, 500K, full 3M triples)\n",
    "2. **Parameter Tuning**: Optimize false triple ratios and validation thresholds\n",
    "3. **Extended Metrics**: Add more sophisticated similarity measures\n",
    "4. **Cross-Validation**: Implement k-fold validation across different data splits\n",
    "5. **Temporal Analysis**: Study how similarity evolves during training\n",
    "\n",
    "**Experiment completed successfully!** All results, graphs, and analyses have been saved to the output directory.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-AGENT SEMANTIC VALIDATION EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d24627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
