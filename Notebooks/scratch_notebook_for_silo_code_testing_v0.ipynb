{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5397d662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Testing Knowledge Graph Agent\n",
      "\n",
      "üß† Knowledge Graph Agent initialized!\n",
      "   Validation: ON\n",
      "   Verbose mode: OFF\n",
      "üìù Loading sample data...\n",
      "üìä Loading triples into knowledge graph...\n",
      "   Processing 5 triples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading triples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 8279.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Knowledge Graph Statistics:\n",
      "==================================================\n",
      "üî¢ Total nodes: 6\n",
      "üîó Total edges: 5\n",
      "üìä Average degree: 1.67\n",
      "\n",
      "üîç Validation Results:\n",
      "   Attempted additions: 5\n",
      "   ‚úÖ Successful: 5\n",
      "   üîÑ Duplicates rejected: 0\n",
      "   ‚ö° Contradictions found: 0\n",
      "   ‚ùå Other errors: 0\n",
      "   üìä Success rate: 100.00%\n",
      "\n",
      "üè∑Ô∏è  Top 10 Relation Types:\n",
      "   IsA: 4\n",
      "   RelatedTo: 1\n",
      "\n",
      "üîç Testing queries...\n",
      "üîç Relations for 'dog':\n",
      "   dog --IsA--> animal (weight: 1.00)\n",
      "   dog --RelatedTo--> cat (weight: 0.80)\n",
      "\n",
      "üõ§Ô∏è  Testing path finding...\n",
      "‚ùå No path found between 'dog' and 'emotion'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Knowledge Graph Agent Implementation\n",
    "# Phase 2: Graph Representation and Validation Logic\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class KnowledgeGraphAgent:\n",
    "    \"\"\"\n",
    "    MVP Knowledge Graph Agent with self-validation and extensible structure\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, validate_on_add=True, verbose=True):\n",
    "        self.graph = nx.MultiDiGraph()  # Allows multiple edges between same nodes\n",
    "        self.validate_on_add = validate_on_add\n",
    "        self.verbose = verbose\n",
    "        self.validation_stats = {\n",
    "            'total_attempted': 0,\n",
    "            'successful_adds': 0,\n",
    "            'duplicates_rejected': 0,\n",
    "            'contradictions_found': 0,\n",
    "            'validation_errors': 0\n",
    "        }\n",
    "        \n",
    "        # Contradiction rules - relations that shouldn't coexist\n",
    "        self.contradiction_rules = {\n",
    "            'Antonym': ['Synonym', 'RelatedTo'],\n",
    "            'Synonym': ['Antonym'],\n",
    "            'Causes': ['Prevents'],\n",
    "            'Prevents': ['Causes']\n",
    "        }\n",
    "        \n",
    "        print(\"üß† Knowledge Graph Agent initialized!\")\n",
    "        print(f\"   Validation: {'ON' if validate_on_add else 'OFF'}\")\n",
    "        print(f\"   Verbose mode: {'ON' if verbose else 'OFF'}\")\n",
    "    \n",
    "    def clean_conceptnet_data(self, df):\n",
    "        \"\"\"\n",
    "        Properly clean ConceptNet data - fixes the string splitting issue\n",
    "        \"\"\"\n",
    "        print(\"üßπ Cleaning ConceptNet data...\")\n",
    "        \n",
    "        def extract_concept(concept_string):\n",
    "            \"\"\"Extract clean concept from ConceptNet URI format\"\"\"\n",
    "            if pd.isna(concept_string):\n",
    "                return None\n",
    "            \n",
    "            # ConceptNet format: /c/en/concept_name/part_of_speech\n",
    "            # We want the concept_name part\n",
    "            parts = str(concept_string).split('/')\n",
    "            if len(parts) >= 4 and parts[1] == 'c' and parts[2] == 'en':\n",
    "                concept = parts[3]\n",
    "                # Handle underscores and clean up\n",
    "                concept = concept.replace('_', ' ')\n",
    "                return concept\n",
    "            return concept_string\n",
    "        \n",
    "        def extract_relation(relation_string):\n",
    "            \"\"\"Extract relation type from ConceptNet URI\"\"\"\n",
    "            if pd.isna(relation_string):\n",
    "                return None\n",
    "            parts = str(relation_string).split('/')\n",
    "            if len(parts) >= 3 and parts[1] == 'r':\n",
    "                return parts[2]\n",
    "            return relation_string\n",
    "        \n",
    "        def extract_weight(weight_string):\n",
    "            \"\"\"Extract numerical weight from JSON string\"\"\"\n",
    "            try:\n",
    "                weight_data = json.loads(weight_string)\n",
    "                return float(weight_data.get('weight', 1.0))\n",
    "            except:\n",
    "                return 1.0\n",
    "        \n",
    "        # Apply cleaning functions\n",
    "        cleaned_df = df.copy()\n",
    "        \n",
    "        print(\"   Extracting concepts and relations...\")\n",
    "        cleaned_df['start_concept'] = df['start'].apply(extract_concept)\n",
    "        cleaned_df['end_concept'] = df['end'].apply(extract_concept)\n",
    "        cleaned_df['relation_type'] = df['relation'].apply(extract_relation)\n",
    "        cleaned_df['edge_weight'] = df['weight'].apply(extract_weight)\n",
    "        \n",
    "        # Filter out invalid entries\n",
    "        initial_count = len(cleaned_df)\n",
    "        cleaned_df = cleaned_df.dropna(subset=['start_concept', 'end_concept', 'relation_type'])\n",
    "        final_count = len(cleaned_df)\n",
    "        \n",
    "        print(f\"   Filtered {initial_count - final_count:,} invalid entries\")\n",
    "        print(f\"   Clean dataset: {final_count:,} triples\")\n",
    "        \n",
    "        return cleaned_df[['start_concept', 'end_concept', 'relation_type', 'edge_weight']]\n",
    "    \n",
    "    def validate_triple(self, start, relation, end, weight=1.0):\n",
    "        \"\"\"\n",
    "        Validate a triple before adding to graph\n",
    "        Returns: (is_valid, reason)\n",
    "        \"\"\"\n",
    "        # Check for duplicates\n",
    "        if self.graph.has_edge(start, end):\n",
    "            existing_edges = self.graph[start][end]\n",
    "            for edge_data in existing_edges.values():\n",
    "                if edge_data.get('relation') == relation:\n",
    "                    return False, f\"Duplicate: {start} --{relation}--> {end}\"\n",
    "        \n",
    "        # Check for contradictions\n",
    "        if relation in self.contradiction_rules:\n",
    "            contradictory_relations = self.contradiction_rules[relation]\n",
    "            \n",
    "            if self.graph.has_edge(start, end):\n",
    "                for edge_data in self.graph[start][end].values():\n",
    "                    if edge_data.get('relation') in contradictory_relations:\n",
    "                        return False, f\"Contradiction: {start} already has {edge_data.get('relation')} with {end}\"\n",
    "        \n",
    "        # Passed all validation checks\n",
    "        return True, \"Valid\"\n",
    "    \n",
    "    def add_triple(self, start, relation, end, weight=1.0, force=False):\n",
    "        \"\"\"\n",
    "        Add a validated triple to the knowledge graph\n",
    "        \"\"\"\n",
    "        self.validation_stats['total_attempted'] += 1\n",
    "        \n",
    "        if not force and self.validate_on_add:\n",
    "            is_valid, reason = self.validate_triple(start, relation, end, weight)\n",
    "            \n",
    "            if not is_valid:\n",
    "                if \"Duplicate\" in reason:\n",
    "                    self.validation_stats['duplicates_rejected'] += 1\n",
    "                elif \"Contradiction\" in reason:\n",
    "                    self.validation_stats['contradictions_found'] += 1\n",
    "                else:\n",
    "                    self.validation_stats['validation_errors'] += 1\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"‚ùå Rejected: {reason}\")\n",
    "                return False\n",
    "        \n",
    "        # Add the triple to graph\n",
    "        self.graph.add_edge(start, end, relation=relation, weight=weight)\n",
    "        self.validation_stats['successful_adds'] += 1\n",
    "        \n",
    "        if self.verbose and self.validation_stats['total_attempted'] % 1000 == 0:\n",
    "            print(f\"‚úÖ Added {self.validation_stats['successful_adds']:,} triples so far...\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def bulk_load_triples(self, df, max_triples=None):\n",
    "        \"\"\"\n",
    "        Efficiently load multiple triples with progress tracking\n",
    "        \"\"\"\n",
    "        print(f\"üìä Loading triples into knowledge graph...\")\n",
    "        \n",
    "        if max_triples:\n",
    "            df = df.head(max_triples)\n",
    "            print(f\"   Limited to first {max_triples:,} triples\")\n",
    "        \n",
    "        total_rows = len(df)\n",
    "        print(f\"   Processing {total_rows:,} triples...\")\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        for idx, row in tqdm(df.iterrows(), total=total_rows, desc=\"Loading triples\"):\n",
    "            self.add_triple(\n",
    "                start=str(row['start_concept']),\n",
    "                relation=str(row['relation_type']),\n",
    "                end=str(row['end_concept']),\n",
    "                weight=float(row['edge_weight'])\n",
    "            )\n",
    "        \n",
    "        self.print_stats()\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Print comprehensive statistics about the knowledge graph\"\"\"\n",
    "        print(\"\\nüìà Knowledge Graph Statistics:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"üî¢ Total nodes: {self.graph.number_of_nodes():,}\")\n",
    "        print(f\"üîó Total edges: {self.graph.number_of_edges():,}\")\n",
    "        print(f\"üìä Average degree: {np.mean([d for n, d in self.graph.degree()]):,.2f}\")\n",
    "        \n",
    "        print(f\"\\nüîç Validation Results:\")\n",
    "        print(f\"   Attempted additions: {self.validation_stats['total_attempted']:,}\")\n",
    "        print(f\"   ‚úÖ Successful: {self.validation_stats['successful_adds']:,}\")\n",
    "        print(f\"   üîÑ Duplicates rejected: {self.validation_stats['duplicates_rejected']:,}\")\n",
    "        print(f\"   ‚ö° Contradictions found: {self.validation_stats['contradictions_found']:,}\")\n",
    "        print(f\"   ‚ùå Other errors: {self.validation_stats['validation_errors']:,}\")\n",
    "        \n",
    "        success_rate = (self.validation_stats['successful_adds'] / max(self.validation_stats['total_attempted'], 1)) * 100\n",
    "        print(f\"   üìä Success rate: {success_rate:.2f}%\")\n",
    "        \n",
    "        # Relation type distribution\n",
    "        relation_counts = Counter()\n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            relation_counts[data.get('relation', 'Unknown')] += 1\n",
    "        \n",
    "        print(f\"\\nüè∑Ô∏è  Top 10 Relation Types:\")\n",
    "        for relation, count in relation_counts.most_common(10):\n",
    "            print(f\"   {relation}: {count:,}\")\n",
    "    \n",
    "    def query_concept(self, concept, max_results=10):\n",
    "        \"\"\"\n",
    "        Query all relations for a given concept\n",
    "        \"\"\"\n",
    "        if concept not in self.graph:\n",
    "            print(f\"‚ùì Concept '{concept}' not found in graph\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"üîç Relations for '{concept}':\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Outgoing relations\n",
    "        for neighbor in list(self.graph.neighbors(concept))[:max_results//2]:\n",
    "            edge_data = self.graph[concept][neighbor]\n",
    "            for edge in edge_data.values():\n",
    "                relation = edge.get('relation', 'Unknown')\n",
    "                weight = edge.get('weight', 1.0)\n",
    "                results.append((concept, relation, neighbor, weight, 'outgoing'))\n",
    "                print(f\"   {concept} --{relation}--> {neighbor} (weight: {weight:.2f})\")\n",
    "        \n",
    "        # Incoming relations\n",
    "        for predecessor in list(self.graph.predecessors(concept))[:max_results//2]:\n",
    "            edge_data = self.graph[predecessor][concept]\n",
    "            for edge in edge_data.values():\n",
    "                relation = edge.get('relation', 'Unknown')\n",
    "                weight = edge.get('weight', 1.0)\n",
    "                results.append((predecessor, relation, concept, weight, 'incoming'))\n",
    "                print(f\"   {predecessor} --{relation}--> {concept} (weight: {weight:.2f})\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def find_path(self, start_concept, end_concept, max_length=3):\n",
    "        \"\"\"\n",
    "        Find connection paths between two concepts\n",
    "        \"\"\"\n",
    "        if start_concept not in self.graph or end_concept not in self.graph:\n",
    "            print(f\"‚ùì One or both concepts not found in graph\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Find shortest path\n",
    "            path = nx.shortest_path(self.graph, start_concept, end_concept, weight=None)\n",
    "            \n",
    "            print(f\"üõ§Ô∏è  Path from '{start_concept}' to '{end_concept}':\")\n",
    "            \n",
    "            # Print the path with relations\n",
    "            for i in range(len(path) - 1):\n",
    "                current = path[i]\n",
    "                next_node = path[i + 1]\n",
    "                \n",
    "                if self.graph.has_edge(current, next_node):\n",
    "                    edge_data = list(self.graph[current][next_node].values())[0]\n",
    "                    relation = edge_data.get('relation', 'Unknown')\n",
    "                    print(f\"   {current} --{relation}--> {next_node}\")\n",
    "                \n",
    "            return path\n",
    "            \n",
    "        except nx.NetworkXNoPath:\n",
    "            print(f\"‚ùå No path found between '{start_concept}' and '{end_concept}'\")\n",
    "            return []\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Testing Knowledge Graph Agent\\n\")\n",
    "    \n",
    "    # Initialize agent\n",
    "    agent = KnowledgeGraphAgent(validate_on_add=True, verbose=False)\n",
    "    \n",
    "    # Test with sample data (replace with your actual cleaned data)\n",
    "    sample_data = pd.DataFrame({\n",
    "        'start_concept': ['dog', 'cat', 'dog', 'happy', 'sad'],\n",
    "        'end_concept': ['animal', 'animal', 'cat', 'emotion', 'emotion'],\n",
    "        'relation_type': ['IsA', 'IsA', 'RelatedTo', 'IsA', 'IsA'],\n",
    "        'edge_weight': [1.0, 1.0, 0.8, 1.0, 1.0]\n",
    "    })\n",
    "    \n",
    "    print(\"üìù Loading sample data...\")\n",
    "    agent.bulk_load_triples(sample_data)\n",
    "    \n",
    "    print(\"\\nüîç Testing queries...\")\n",
    "    agent.query_concept('dog')\n",
    "    \n",
    "    print(\"\\nüõ§Ô∏è  Testing path finding...\")\n",
    "    agent.find_path('dog', 'emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d0049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
