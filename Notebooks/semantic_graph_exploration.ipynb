{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1561143b",
   "metadata": {},
   "source": [
    "# Semantic Knowledge Graph Exploration\n",
    "\n",
    "This notebook is dedicated to exploring and analyzing the trained semantic knowledge graph (`nx_semantic_final.graphml`). It provides comprehensive tools for:\n",
    "\n",
    "- Loading and analyzing the graph statistics\n",
    "- Exploring concept relationships and semantic paths\n",
    "- Discovering patterns and extracting taxonomies\n",
    "- Visualizing concept neighborhoods\n",
    "- Performing advanced semantic queries\n",
    "- Exporting results for downstream applications\n",
    "\n",
    "The graph was created using hyper-training on ConceptNet data with semantic enrichment including high-confidence flags, transitivity scores, and centrality measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce0841",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load the Semantic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained semantic graph\n",
    "graph_path = os.path.join('..', 'Data', 'Output', 'nx_semantic_final.graphml')\n",
    "\n",
    "print(f\"Loading semantic graph from: {graph_path}\")\n",
    "G = nx.read_graphml(graph_path)\n",
    "\n",
    "print(f\"‚úÖ Graph loaded successfully!\")\n",
    "print(f\"üìä Nodes: {G.number_of_nodes():,}\")\n",
    "print(f\"üìä Edges: {G.number_of_edges():,}\")\n",
    "print(f\"üìä Graph type: {type(G).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced136d7",
   "metadata": {},
   "source": [
    "## 2. Knowledge Graph Explorer Class\n",
    "\n",
    "This comprehensive explorer class provides all the tools needed for semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticGraphExplorer:\n",
    "    \"\"\"\n",
    "    Comprehensive tools for exploring and analyzing a semantic knowledge graph.\n",
    "    Optimized for ConceptNet-style graphs with relation types and weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        \"\"\"Initialize the explorer with a NetworkX graph\"\"\"\n",
    "        self.graph = graph\n",
    "        self.relation_types = self._get_all_relation_types()\n",
    "        self._centrality_cache = {}\n",
    "        \n",
    "        print(f\"üîç Explorer initialized for graph with {self.graph.number_of_nodes():,} nodes\")\n",
    "        print(f\"üìã Found {len(self.relation_types)} unique relation types\")\n",
    "        \n",
    "    def _get_all_relation_types(self):\n",
    "        \"\"\"Get all unique relation types in the graph\"\"\"\n",
    "        relation_types = set()\n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            if 'relation' in data:\n",
    "                relation_types.add(data['relation'])\n",
    "        return sorted(list(relation_types))\n",
    "    \n",
    "    def get_graph_overview(self):\n",
    "        \"\"\"Get comprehensive statistics about the graph\"\"\"\n",
    "        print(\"üìä GRAPH OVERVIEW\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Basic stats\n",
    "        stats = {\n",
    "            'nodes': self.graph.number_of_nodes(),\n",
    "            'edges': self.graph.number_of_edges(),\n",
    "            'density': nx.density(self.graph),\n",
    "            'is_directed': nx.is_directed(self.graph),\n",
    "            'is_multigraph': nx.is_multigraph(self.graph)\n",
    "        }\n",
    "        \n",
    "        for key, value in stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value:,}\" if isinstance(value, int) else f\"  {key}: {value}\")\n",
    "        \n",
    "        # Degree statistics\n",
    "        degrees = [d for n, d in self.graph.degree()]\n",
    "        print(f\"\\nüìà DEGREE STATISTICS\")\n",
    "        print(f\"  Average degree: {np.mean(degrees):.2f}\")\n",
    "        print(f\"  Median degree: {np.median(degrees):.2f}\")\n",
    "        print(f\"  Max degree: {max(degrees):,}\")\n",
    "        print(f\"  Min degree: {min(degrees):,}\")\n",
    "        \n",
    "        # Weight statistics (if available)\n",
    "        weights = [data.get('weight', 0) for _, _, data in self.graph.edges(data=True)]\n",
    "        if weights and any(w > 0 for w in weights):\n",
    "            print(f\"\\n‚öñÔ∏è  WEIGHT STATISTICS\")\n",
    "            print(f\"  Average weight: {np.mean(weights):.3f}\")\n",
    "            print(f\"  Median weight: {np.median(weights):.3f}\")\n",
    "            print(f\"  Max weight: {max(weights):.3f}\")\n",
    "            print(f\"  Min weight: {min(weights):.3f}\")\n",
    "        \n",
    "        # Relation type distribution\n",
    "        relation_counts = Counter()\n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            relation = data.get('relation', 'unknown')\n",
    "            relation_counts[relation] += 1\n",
    "        \n",
    "        print(f\"\\nüîó TOP 10 RELATION TYPES\")\n",
    "        for relation, count in relation_counts.most_common(10):\n",
    "            print(f\"  {relation}: {count:,} ({count/self.graph.number_of_edges()*100:.1f}%)\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def explore_concept(self, concept, relation_filter=None, min_weight=0.0, limit=20, show_enrichment=True):\n",
    "        \"\"\"Explore all relationships for a given concept\"\"\"\n",
    "        if concept not in self.graph:\n",
    "            return f\"‚ùå Concept '{concept}' not found in the graph.\"\n",
    "        \n",
    "        print(f\"üîç EXPLORING CONCEPT: '{concept}'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Collect all edges\n",
    "        edges = []\n",
    "        \n",
    "        # Outgoing edges\n",
    "        for _, target, data in self.graph.out_edges(concept, data=True):\n",
    "            if self._edge_matches_filter(data, relation_filter, min_weight):\n",
    "                edge_info = {\n",
    "                    'source': concept,\n",
    "                    'target': target,\n",
    "                    'relation': data.get('relation', 'unknown'),\n",
    "                    'weight': data.get('weight', 0.0),\n",
    "                    'direction': 'outgoing'\n",
    "                }\n",
    "                if show_enrichment:\n",
    "                    edge_info.update({\n",
    "                        'high_confidence': data.get('high_confidence', False),\n",
    "                        'iteration_added': data.get('iteration_added', 'unknown')\n",
    "                    })\n",
    "                edges.append(edge_info)\n",
    "        \n",
    "        # Incoming edges\n",
    "        for source, _, data in self.graph.in_edges(concept, data=True):\n",
    "            if self._edge_matches_filter(data, relation_filter, min_weight):\n",
    "                edge_info = {\n",
    "                    'source': source,\n",
    "                    'target': concept,\n",
    "                    'relation': data.get('relation', 'unknown'),\n",
    "                    'weight': data.get('weight', 0.0),\n",
    "                    'direction': 'incoming'\n",
    "                }\n",
    "                if show_enrichment:\n",
    "                    edge_info.update({\n",
    "                        'high_confidence': data.get('high_confidence', False),\n",
    "                        'iteration_added': data.get('iteration_added', 'unknown')\n",
    "                    })\n",
    "                edges.append(edge_info)\n",
    "        \n",
    "        # Convert to DataFrame and sort\n",
    "        if not edges:\n",
    "            print(f\"No edges found matching the criteria.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(edges)\n",
    "        df = df.sort_values('weight', ascending=False).head(limit)\n",
    "        \n",
    "        print(f\"üìä Found {len(edges)} total relationships, showing top {len(df)}\")\n",
    "        print(f\"üìä Degree: {self.graph.degree(concept)} (in: {self.graph.in_degree(concept)}, out: {self.graph.out_degree(concept)})\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _edge_matches_filter(self, data, relation_filter, min_weight):\n",
    "        \"\"\"Check if an edge matches the given filters\"\"\"\n",
    "        if relation_filter and data.get('relation') not in relation_filter:\n",
    "            return False\n",
    "        if data.get('weight', 0) < min_weight:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def find_semantic_path(self, source, target, relation_filter=None, max_length=4):\n",
    "        \"\"\"Find the shortest semantic path between two concepts\"\"\"\n",
    "        if source not in self.graph:\n",
    "            return f\"‚ùå Source concept '{source}' not found\"\n",
    "        if target not in self.graph:\n",
    "            return f\"‚ùå Target concept '{target}' not found\"\n",
    "        \n",
    "        print(f\"üîç FINDING PATH: '{source}' ‚Üí '{target}'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create filtered graph if needed\n",
    "        search_graph = self.graph\n",
    "        if relation_filter:\n",
    "            search_graph = nx.MultiDiGraph()\n",
    "            for u, v, key, data in self.graph.edges(keys=True, data=True):\n",
    "                if data.get('relation') in relation_filter:\n",
    "                    search_graph.add_edge(u, v, key=key, **data)\n",
    "            print(f\"üîç Using filtered graph with relations: {relation_filter}\")\n",
    "        \n",
    "        try:\n",
    "            # Find shortest path weighted by inverse of edge weight\n",
    "            path = nx.shortest_path(\n",
    "                search_graph, source, target,\n",
    "                weight=lambda u, v, data: 1.0 / max(data.get('weight', 0.1), 0.1)\n",
    "            )\n",
    "            \n",
    "            # Construct detailed path with relations\n",
    "            detailed_path = []\n",
    "            total_weight = 0\n",
    "            \n",
    "            for i in range(len(path) - 1):\n",
    "                u, v = path[i], path[i + 1]\n",
    "                edges = search_graph.get_edge_data(u, v)\n",
    "                \n",
    "                if edges:\n",
    "                    # Get the best edge (highest weight)\n",
    "                    best_key = max(edges.keys(), key=lambda k: edges[k].get('weight', 0))\n",
    "                    best_edge = edges[best_key]\n",
    "                    \n",
    "                    step_info = {\n",
    "                        'step': i + 1,\n",
    "                        'from': u,\n",
    "                        'relation': best_edge.get('relation', 'unknown'),\n",
    "                        'to': v,\n",
    "                        'weight': best_edge.get('weight', 0.0),\n",
    "                        'high_confidence': best_edge.get('high_confidence', False)\n",
    "                    }\n",
    "                    detailed_path.append(step_info)\n",
    "                    total_weight += step_info['weight']\n",
    "            \n",
    "            print(f\"‚úÖ Path found! Length: {len(path) - 1} steps\")\n",
    "            print(f\"üìä Total path weight: {total_weight:.3f}\")\n",
    "            print(f\"üìä Average step weight: {total_weight / len(detailed_path):.3f}\")\n",
    "            \n",
    "            return pd.DataFrame(detailed_path)\n",
    "            \n",
    "        except nx.NetworkXNoPath:\n",
    "            print(f\"‚ùå No path found between '{source}' and '{target}'\")\n",
    "            return None\n",
    "    \n",
    "    def get_top_concepts(self, n=20, measure='degree', force_recalculate=False):\n",
    "        \"\"\"Get top concepts by various centrality measures\"\"\"\n",
    "        print(f\"üèÜ TOP {n} CONCEPTS BY {measure.upper()}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if measure in self._centrality_cache and not force_recalculate:\n",
    "            centrality = self._centrality_cache[measure]\n",
    "        else:\n",
    "            if measure == 'degree':\n",
    "                centrality = dict(self.graph.degree())\n",
    "            elif measure == 'in_degree':\n",
    "                centrality = dict(self.graph.in_degree())\n",
    "            elif measure == 'out_degree':\n",
    "                centrality = dict(self.graph.out_degree())\n",
    "            elif measure == 'pagerank':\n",
    "                print(\"üîÑ Computing PageRank (this may take a while for large graphs)...\")\n",
    "                centrality = nx.pagerank(self.graph, alpha=0.85, weight='weight')\n",
    "            elif measure == 'betweenness':\n",
    "                print(\"üîÑ Computing Betweenness Centrality (this may take a while)...\")\n",
    "                centrality = nx.betweenness_centrality(self.graph, weight='weight')\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown centrality measure: {measure}\")\n",
    "            \n",
    "            self._centrality_cache[measure] = centrality\n",
    "        \n",
    "        # Convert to DataFrame and get top N\n",
    "        df = pd.DataFrame(centrality.items(), columns=['concept', 'score'])\n",
    "        top_df = df.nlargest(n, 'score')\n",
    "        \n",
    "        print(f\"üìä Showing top {len(top_df)} concepts\")\n",
    "        return top_df\n",
    "    \n",
    "    def analyze_relation_types(self, top_n=15):\n",
    "        \"\"\"Analyze the distribution and characteristics of relation types\"\"\"\n",
    "        print(f\"üîó RELATION TYPE ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        relation_stats = defaultdict(lambda: {\n",
    "            'count': 0,\n",
    "            'weights': [],\n",
    "            'high_confidence_count': 0\n",
    "        })\n",
    "        \n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            relation = data.get('relation', 'unknown')\n",
    "            weight = data.get('weight', 0.0)\n",
    "            high_conf = data.get('high_confidence', False)\n",
    "            \n",
    "            relation_stats[relation]['count'] += 1\n",
    "            relation_stats[relation]['weights'].append(weight)\n",
    "            if high_conf:\n",
    "                relation_stats[relation]['high_confidence_count'] += 1\n",
    "        \n",
    "        # Create summary DataFrame\n",
    "        summary_data = []\n",
    "        for relation, stats in relation_stats.items():\n",
    "            weights = stats['weights']\n",
    "            summary_data.append({\n",
    "                'relation': relation,\n",
    "                'count': stats['count'],\n",
    "                'percentage': stats['count'] / self.graph.number_of_edges() * 100,\n",
    "                'avg_weight': np.mean(weights) if weights else 0,\n",
    "                'high_confidence_rate': stats['high_confidence_count'] / stats['count'] * 100 if stats['count'] > 0 else 0\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(summary_data)\n",
    "        df = df.sort_values('count', ascending=False).head(top_n)\n",
    "        \n",
    "        print(f\"üìä Found {len(relation_stats)} unique relation types\")\n",
    "        print(f\"üìä Showing top {len(df)} by frequency\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def extract_concept_taxonomy(self, root_concept, relation_types=['IsA'], max_depth=4, max_children=10):\n",
    "        \"\"\"Extract a hierarchical taxonomy starting from a root concept\"\"\"\n",
    "        if root_concept not in self.graph:\n",
    "            return f\"‚ùå Root concept '{root_concept}' not found\"\n",
    "        \n",
    "        print(f\"üå≥ EXTRACTING TAXONOMY FROM: '{root_concept}'\")\n",
    "        print(f\"üîó Using relations: {relation_types}\")\n",
    "        print(f\"üìè Max depth: {max_depth}, Max children per node: {max_children}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        def build_tree(concept, current_depth=0, visited=None):\n",
    "            if visited is None:\n",
    "                visited = set()\n",
    "            \n",
    "            if current_depth >= max_depth or concept in visited:\n",
    "                return {}\n",
    "            \n",
    "            visited.add(concept)\n",
    "            tree = {}\n",
    "            \n",
    "            # Get children for this concept\n",
    "            children = []\n",
    "            for _, target, data in self.graph.out_edges(concept, data=True):\n",
    "                if data.get('relation') in relation_types:\n",
    "                    children.append((target, data.get('weight', 0.0)))\n",
    "            \n",
    "            # Sort by weight and limit\n",
    "            children.sort(key=lambda x: x[1], reverse=True)\n",
    "            children = children[:max_children]\n",
    "            \n",
    "            for child, weight in children:\n",
    "                tree[child] = {\n",
    "                    'weight': weight,\n",
    "                    'children': build_tree(child, current_depth + 1, visited.copy())\n",
    "                }\n",
    "            \n",
    "            return tree\n",
    "        \n",
    "        taxonomy = build_tree(root_concept)\n",
    "        \n",
    "        # Count total nodes in taxonomy\n",
    "        def count_nodes(tree):\n",
    "            count = len(tree)\n",
    "            for child_data in tree.values():\n",
    "                if isinstance(child_data, dict) and 'children' in child_data:\n",
    "                    count += count_nodes(child_data['children'])\n",
    "            return count\n",
    "        \n",
    "        total_nodes = count_nodes(taxonomy)\n",
    "        print(f\"‚úÖ Extracted taxonomy with {total_nodes} nodes\")\n",
    "        \n",
    "        return {root_concept: taxonomy}\n",
    "    \n",
    "    def search_concepts(self, pattern, limit=20, use_regex=False):\n",
    "        \"\"\"Search for concepts matching a pattern\"\"\"\n",
    "        import re\n",
    "        \n",
    "        print(f\"üîç SEARCHING CONCEPTS: '{pattern}'\")\n",
    "        print(f\"üìä Pattern matching: {'Regex' if use_regex else 'Substring'}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        if use_regex:\n",
    "            try:\n",
    "                regex = re.compile(pattern, re.IGNORECASE)\n",
    "                for node in self.graph.nodes():\n",
    "                    if regex.search(str(node)):\n",
    "                        matches.append({\n",
    "                            'concept': node,\n",
    "                            'degree': self.graph.degree(node)\n",
    "                        })\n",
    "                        if len(matches) >= limit:\n",
    "                            break\n",
    "            except re.error as e:\n",
    "                return f\"‚ùå Invalid regex pattern: {e}\"\n",
    "        else:\n",
    "            pattern_lower = pattern.lower()\n",
    "            for node in self.graph.nodes():\n",
    "                if pattern_lower in str(node).lower():\n",
    "                    matches.append({\n",
    "                        'concept': node,\n",
    "                        'degree': self.graph.degree(node)\n",
    "                    })\n",
    "                    if len(matches) >= limit:\n",
    "                        break\n",
    "        \n",
    "        if not matches:\n",
    "            print(f\"‚ùå No concepts found matching '{pattern}'\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(matches)\n",
    "        df = df.sort_values('degree', ascending=False)\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(matches)} matching concepts\")\n",
    "        return df\n",
    "\n",
    "print(\"‚úÖ SemanticGraphExplorer class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b3f58",
   "metadata": {},
   "source": [
    "## 3. Initialize Explorer and Get Graph Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c96c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the semantic graph explorer\n",
    "explorer = SemanticGraphExplorer(G)\n",
    "\n",
    "# Get comprehensive graph overview\n",
    "overview = explorer.get_graph_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0b0cd",
   "metadata": {},
   "source": [
    "## 4. Explore Individual Concepts\n",
    "\n",
    "Let's explore some interesting concepts in detail to understand their semantic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore a technology concept\n",
    "computer_relations = explorer.explore_concept('computer', min_weight=1.0, limit=15)\n",
    "display(computer_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore an animal concept\n",
    "dog_relations = explorer.explore_concept('dog', min_weight=1.5, limit=15)\n",
    "display(dog_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3319c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore only specific relation types for a concept\n",
    "human_isa = explorer.explore_concept('human', relation_filter=['IsA', 'CapableOf'], min_weight=1.0, limit=10)\n",
    "display(human_isa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e5cc6",
   "metadata": {},
   "source": [
    "## 5. Semantic Path Finding\n",
    "\n",
    "Discover how concepts are semantically connected through chains of relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find path between seemingly unrelated concepts\n",
    "path1 = explorer.find_semantic_path('dog', 'computer', max_length=4)\n",
    "if path1 is not None:\n",
    "    display(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find path using only specific relation types\n",
    "path2 = explorer.find_semantic_path('animal', 'science', relation_filter=['RelatedTo', 'UsedFor'], max_length=3)\n",
    "if path2 is not None:\n",
    "    display(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc036f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find path between abstract concepts\n",
    "path3 = explorer.find_semantic_path('happiness', 'success', max_length=3)\n",
    "if path3 is not None:\n",
    "    display(path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d2a3c",
   "metadata": {},
   "source": [
    "## 6. Discover Most Important Concepts\n",
    "\n",
    "Find the most central and influential concepts in the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c161ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top concepts by total degree (most connected)\n",
    "top_by_degree = explorer.get_top_concepts(20, 'degree')\n",
    "display(top_by_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332656b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top concepts by out-degree (most outgoing relationships)\n",
    "top_by_out_degree = explorer.get_top_concepts(15, 'out_degree')\n",
    "display(top_by_out_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad99bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top concepts by PageRank (most influential)\n",
    "# Note: This may take a while for large graphs\n",
    "top_by_pagerank = explorer.get_top_concepts(15, 'pagerank')\n",
    "display(top_by_pagerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f473f",
   "metadata": {},
   "source": [
    "## 7. Analyze Relation Types\n",
    "\n",
    "Understand the distribution and characteristics of different semantic relation types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d145970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive relation type analysis\n",
    "relation_analysis = explorer.analyze_relation_types(top_n=20)\n",
    "display(relation_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relation type distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Top 10 relations by count\n",
    "top_relations = relation_analysis.head(10)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "bars = plt.bar(range(len(top_relations)), top_relations['count'])\n",
    "plt.xticks(range(len(top_relations)), top_relations['relation'], rotation=45, ha='right')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 10 Relation Types by Frequency')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Color bars by percentage\n",
    "colors = plt.cm.viridis(top_relations['percentage'] / top_relations['percentage'].max())\n",
    "for bar, color in zip(bars, colors):\n",
    "    bar.set_color(color)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(top_relations['avg_weight'], top_relations['high_confidence_rate'], \n",
    "           s=top_relations['count']/100, alpha=0.6)\n",
    "plt.xlabel('Average Weight')\n",
    "plt.ylabel('High Confidence Rate (%)')\n",
    "plt.title('Relation Quality: Weight vs High Confidence Rate (bubble size = frequency)')\n",
    "\n",
    "# Add labels for interesting points\n",
    "for _, row in top_relations.iterrows():\n",
    "    if row['high_confidence_rate'] > 50 or row['avg_weight'] > 2:\n",
    "        plt.annotate(row['relation'], \n",
    "                    (row['avg_weight'], row['high_confidence_rate']),\n",
    "                    xytext=(5, 5), textcoords='offset points',\n",
    "                    fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa90534",
   "metadata": {},
   "source": [
    "## 8. Extract Semantic Taxonomies\n",
    "\n",
    "Build hierarchical taxonomies from specific root concepts using 'IsA' relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract animal taxonomy\n",
    "animal_taxonomy = explorer.extract_concept_taxonomy('animal', relation_types=['IsA'], max_depth=3, max_children=8)\n",
    "\n",
    "# Pretty print the taxonomy\n",
    "def print_taxonomy(taxonomy, indent=0):\n",
    "    for concept, data in taxonomy.items():\n",
    "        print(\"  \" * indent + f\"üìå {concept}\")\n",
    "        if isinstance(data, dict) and 'children' in data:\n",
    "            print_taxonomy(data['children'], indent + 1)\n",
    "        elif isinstance(data, dict):\n",
    "            print_taxonomy(data, indent + 1)\n",
    "\n",
    "print(\"üå≥ ANIMAL TAXONOMY:\")\n",
    "print_taxonomy(animal_taxonomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeaaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract technology taxonomy\n",
    "tech_taxonomy = explorer.extract_concept_taxonomy('technology', relation_types=['IsA', 'InstanceOf'], max_depth=3, max_children=6)\n",
    "\n",
    "print(\"üå≥ TECHNOLOGY TAXONOMY:\")\n",
    "print_taxonomy(tech_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c5051",
   "metadata": {},
   "source": [
    "## 9. Concept Search and Discovery\n",
    "\n",
    "Search for concepts using patterns and discover related terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51277a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for concepts containing 'artificial'\n",
    "ai_concepts = explorer.search_concepts('artificial', limit=15)\n",
    "display(ai_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search using regex for concepts ending in 'science'\n",
    "science_concepts = explorer.search_concepts(r'.*science$', limit=15, use_regex=True)\n",
    "display(science_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765925a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for emotion-related concepts\n",
    "emotion_concepts = explorer.search_concepts('emotion', limit=10)\n",
    "display(emotion_concepts)\n",
    "\n",
    "# Explore relationships of the most connected emotion concept\n",
    "if not emotion_concepts.empty:\n",
    "    top_emotion = emotion_concepts.iloc[0]['concept']\n",
    "    emotion_relations = explorer.explore_concept(top_emotion, min_weight=1.0, limit=10)\n",
    "    print(f\"\\nüîç Exploring '{top_emotion}':\")\n",
    "    display(emotion_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f226c",
   "metadata": {},
   "source": [
    "## 10. Export Results for Further Analysis\n",
    "\n",
    "Save interesting findings to files for use in other applications or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export top concepts to CSV\n",
    "output_dir = os.path.join('..', 'Data', 'Output')\n",
    "\n",
    "# Export top concepts by different measures\n",
    "top_by_degree.to_csv(os.path.join(output_dir, 'top_concepts_by_degree.csv'), index=False)\n",
    "top_by_pagerank.to_csv(os.path.join(output_dir, 'top_concepts_by_pagerank.csv'), index=False)\n",
    "\n",
    "# Export relation analysis\n",
    "relation_analysis.to_csv(os.path.join(output_dir, 'relation_type_analysis.csv'), index=False)\n",
    "\n",
    "# Export concept explorations\n",
    "computer_relations.to_csv(os.path.join(output_dir, 'computer_relationships.csv'), index=False)\n",
    "dog_relations.to_csv(os.path.join(output_dir, 'dog_relationships.csv'), index=False)\n",
    "\n",
    "# Export taxonomies as JSON\n",
    "with open(os.path.join(output_dir, 'animal_taxonomy.json'), 'w') as f:\n",
    "    json.dump(animal_taxonomy, f, indent=2)\n",
    "\n",
    "with open(os.path.join(output_dir, 'tech_taxonomy.json'), 'w') as f:\n",
    "    json.dump(tech_taxonomy, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Results exported to Data/Output/\")\n",
    "print(\"üìÅ Files created:\")\n",
    "print(\"  - top_concepts_by_degree.csv\")\n",
    "print(\"  - top_concepts_by_pagerank.csv\")\n",
    "print(\"  - relation_type_analysis.csv\")\n",
    "print(\"  - computer_relationships.csv\")\n",
    "print(\"  - dog_relationships.csv\")\n",
    "print(\"  - animal_taxonomy.json\")\n",
    "print(\"  - tech_taxonomy.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdde636",
   "metadata": {},
   "source": [
    "## 11. Advanced Analysis and Insights\n",
    "\n",
    "Perform deeper analysis to extract insights about the semantic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze high-confidence edges\n",
    "high_conf_count = sum(1 for _, _, data in G.edges(data=True) if data.get('high_confidence', False))\n",
    "total_edges = G.number_of_edges()\n",
    "high_conf_percentage = high_conf_count / total_edges * 100\n",
    "\n",
    "print(f\"üìä HIGH-CONFIDENCE EDGE ANALYSIS\")\n",
    "print(f\"Total edges: {total_edges:,}\")\n",
    "print(f\"High-confidence edges: {high_conf_count:,} ({high_conf_percentage:.1f}%)\")\n",
    "\n",
    "# Analyze enrichment attributes by iteration\n",
    "iteration_counts = Counter()\n",
    "for _, _, data in G.edges(data=True):\n",
    "    iteration = data.get('iteration_added', 'unknown')\n",
    "    iteration_counts[iteration] += 1\n",
    "\n",
    "print(f\"\\nüìä EDGES BY TRAINING ITERATION\")\n",
    "for iteration, count in sorted(iteration_counts.items()):\n",
    "    percentage = count / total_edges * 100\n",
    "    print(f\"Iteration {iteration}: {count:,} edges ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find concepts that are hubs (high out-degree) vs authorities (high in-degree)\n",
    "out_degrees = dict(G.out_degree())\n",
    "in_degrees = dict(G.in_degree())\n",
    "\n",
    "# Calculate hub vs authority ratio\n",
    "hub_authority_ratio = {}\n",
    "for node in G.nodes():\n",
    "    out_deg = out_degrees[node]\n",
    "    in_deg = in_degrees[node]\n",
    "    if in_deg > 0:\n",
    "        hub_authority_ratio[node] = out_deg / in_deg\n",
    "    else:\n",
    "        hub_authority_ratio[node] = float('inf') if out_deg > 0 else 0\n",
    "\n",
    "# Find top hubs (high out-degree, low in-degree ratio)\n",
    "top_hubs = sorted(hub_authority_ratio.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"üåü TOP HUBS (concepts that point to many others):\")\n",
    "for concept, ratio in top_hubs:\n",
    "    if ratio != float('inf'):\n",
    "        print(f\"  {concept}: out={out_degrees[concept]}, in={in_degrees[concept]}, ratio={ratio:.2f}\")\n",
    "\n",
    "# Find top authorities (low out-degree, high in-degree ratio)\n",
    "authority_scores = {node: 1/ratio if ratio > 0 and ratio != float('inf') else 0 \n",
    "                   for node, ratio in hub_authority_ratio.items()}\n",
    "top_authorities = sorted(authority_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nüéØ TOP AUTHORITIES (concepts that many others point to):\")\n",
    "for concept, score in top_authorities:\n",
    "    if score > 0:\n",
    "        print(f\"  {concept}: out={out_degrees[concept]}, in={in_degrees[concept]}, authority_score={score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f5e03",
   "metadata": {},
   "source": [
    "## 12. Interactive Exploration\n",
    "\n",
    "Use this section for ad-hoc exploration and testing new queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive exploration cell - modify as needed\n",
    "# Try exploring different concepts or finding paths between interesting pairs\n",
    "\n",
    "concept_to_explore = 'love'  # Change this to any concept you want to explore\n",
    "relations = explorer.explore_concept(concept_to_explore, min_weight=1.0, limit=12)\n",
    "display(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try finding interesting semantic paths\n",
    "source_concept = 'music'  # Change these to explore different paths\n",
    "target_concept = 'mathematics'\n",
    "\n",
    "path = explorer.find_semantic_path(source_concept, target_concept, max_length=4)\n",
    "if path is not None:\n",
    "    display(path)\n",
    "else:\n",
    "    print(f\"No path found between '{source_concept}' and '{target_concept}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdbda09",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive tools for exploring your semantic knowledge graph. The graph contains rich semantic relationships with:\n",
    "\n",
    "- **Semantic enrichment**: High-confidence flags, iteration tracking, and centrality measures\n",
    "- **Multiple relation types**: Covering various semantic relationships like IsA, RelatedTo, CapableOf, etc.\n",
    "- **Quality filtering**: Edges are weighted and filtered based on confidence and training iterations\n",
    "\n",
    "**Key findings to explore further:**\n",
    "1. The most central concepts in your domain\n",
    "2. Semantic paths between seemingly unrelated concepts\n",
    "3. Hierarchical taxonomies for specific domains\n",
    "4. Patterns in relation types and their characteristics\n",
    "\n",
    "**Next steps:**\n",
    "- Use the exported data for downstream applications\n",
    "- Integrate with NLP models for semantic search or QA\n",
    "- Build interactive visualizations\n",
    "- Expand the analysis with domain-specific queries"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
